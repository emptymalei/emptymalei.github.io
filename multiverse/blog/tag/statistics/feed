<?xml version="1.0" encoding="UTF-8"?><rss version="2.0"
	xmlns:content="http://purl.org/rss/1.0/modules/content/"
	xmlns:wfw="http://wellformedweb.org/CommentAPI/"
	xmlns:dc="http://purl.org/dc/elements/1.1/"
	xmlns:atom="http://www.w3.org/2005/Atom"
	xmlns:sy="http://purl.org/rss/1.0/modules/syndication/"
	xmlns:slash="http://purl.org/rss/1.0/modules/slash/"
	>

<channel>
	<title>时见疏星 &#187; Statistics</title>
	<atom:link href="http://multiverse.lamost.org/blog/tag/statistics/feed" rel="self" type="application/rss+xml" />
	<link>http://multiverse.lamost.org/blog</link>
	<description>流年暗中偷换</description>
	<lastBuildDate>Tue, 28 Apr 2015 15:55:56 +0000</lastBuildDate>
	<language>en-US</language>
	<sy:updatePeriod>hourly</sy:updatePeriod>
	<sy:updateFrequency>1</sy:updateFrequency>
	<generator>http://wordpress.org/?v=4.2.2</generator>
	<item>
		<title>一张图理清热力学势之间的关系</title>
		<link>http://multiverse.lamost.org/blog/6266</link>
		<comments>http://multiverse.lamost.org/blog/6266#comments</comments>
		<pubDate>Sat, 22 Feb 2014 06:16:55 +0000</pubDate>
		<dc:creator><![CDATA[时见疏星]]></dc:creator>
				<category><![CDATA[天尽头的纸条]]></category>
		<category><![CDATA[Math]]></category>
		<category><![CDATA[Statistical Physics]]></category>
		<category><![CDATA[Statistics]]></category>
		<category><![CDATA[物理]]></category>

		<guid isPermaLink="false">http://multiverse.lamost.org/blog/?p=6266</guid>
		<description><![CDATA[今天办公室有个人跟我说她总是记不住 thermodynamic potential 之间的关系。于是我就给她讲了 Legendre transformation. 我想了想，热力学势（特性函数）可以总结成下面的一张图。 这篇文章就是简要的解释一下这张图。这篇文章只是给热力学的初学者看的，如果你已经学过理论力学或者统计物理的，我就是在浪费你的时间了。 本科学习的热力学主要的内容无非就是包括下面几部分（A Modern Course in Statistical Physics by L. E. Reichl）： Thermodynamic variables; extensive, intensive, neither; Equations of state; Four fundamental laws of thermodynamics; Thermodynamics potentials Phase transitions Response Stability 整个的思路跟 mechanics 类似。先搞清楚如何描述一个体系，包括状态和&#8221;kinematics&#8221;，这里...<div class='yarpp-related-rss'>
<hr />
<big><strong><font color="#ff6600">长程相关文章:</font></strong></big><ol>
<li><a href="http://multiverse.lamost.org/blog/6250" rel="bookmark" title="心理叠加态：从量子爱情到人的所有心理">心理叠加态：从量子爱情到人的所有心理 </a><hr /></li>
<li><a href="http://multiverse.lamost.org/blog/2292" rel="bookmark" title="Relativistic Thermal Dynamics | 相对论性热力学">Relativistic Thermal Dynamics | 相对论性热力学 </a><hr /></li>
<li><a href="http://multiverse.lamost.org/blog/2284" rel="bookmark" title="How to construct the metric tensor?">How to construct the metric tensor? </a><hr /></li>
</ol>
</div>
]]></description>
				<content:encoded><![CDATA[<p>今天办公室有个人跟我说她总是记不住 thermodynamic potential 之间的关系。于是我就给她讲了 Legendre transformation. 我想了想，热力学势（特性函数）可以总结成下面的一张图。</p>
<p><a href="http://multiverse.lamost.org/blog/wp-content/uploads/2014/02/thermodynamicPotentials1.png"><img src="http://multiverse.lamost.org/blog/wp-content/uploads/2014/02/thermodynamicPotentials1.png" alt="Thermodynamic Potentials" /></a></p>
<p>这篇文章就是简要的解释一下这张图。这篇文章只是给热力学的初学者看的，如果你已经学过理论力学或者统计物理的，我就是在浪费你的时间了。<br />
<span id="more-6266"></span><br />
本科学习的热力学主要的内容无非就是包括下面几部分（<em>A Modern Course in Statistical Physics</em> by L. E. Reichl）：</p>
<ol>
<li>Thermodynamic variables; extensive, intensive, neither;</li>
<li>Equations of state;</li>
<li>Four fundamental laws of thermodynamics;</li>
<li>Thermodynamics potentials</li>
<li>Phase transitions</li>
<li>Response</li>
<li>Stability</li>
</ol>
<p>整个的思路跟 mechanics 类似。先搞清楚如何描述一个体系，包括状态和&#8221;kinematics&#8221;，这里 &#8220;kinematics&#8221;包括状态方程和特性函数。其次，提出“第一性原理”：四条热力学定律。然后研究“动力学”：相变、响应和稳定性。</p>
<p>如果学的时候用的是汪志诚老先生的的书，在热力学势的地方会有些困惑。汪志诚老先生的书读起来很顺，但是由于很薄，很多东西没详细展开，热力学势就是其中一点。热力学势的关键除了搞清楚每个势的意义，另外就是要搞清楚哪些是变量。而确定哪些是变量的就是 Legendre transformation. 所以，要搞清楚这些势，可以从 Legendre transformation 下手。</p>
<h2>Legendre Transformation</h2>
<p>Legendre transformation 的基本定义在《经典力学的数学方法》中有，我写过一篇<a href="http://book.douban.com/people/emptymalei/annotation/1728598/" target="_blank">简单的笔记</a>，当时总结的不是很清楚，而且如果仅仅是为了比较<strong>肤浅</strong>的理清楚热力学势的关系，不太需要很严格的定义。所以我重新功利的说一下。</p>
<p>如果我们有一个函数 $U(T)$，其中 $T$ 是自变量，而我们想要得到另一个函数 $H(S)$，自变量变成了 $S$，那么在热力学势的范围内，我们只需要做这样的变换：</p>
<p>$$H(S) = U -TS$$</p>
<p>当然，这个变换跟书里面的 Legendre transformation 差一个符号，这个并不重要，定义成差一个负号，更加符合物理的理解，因为这些都对应的能量，增加一个量看能量的变化，如果加了负号，增量正好相反，反而不便。</p>
<p>这样我们说 $U(T)$ 和 $H(T)$ 对偶。（在 mechanics 里面，Lagrangian 和 Hamiltonian 也是对偶，理论力学里面最最重要的一个关系之一。）</p>
<h2>Coupling</h2>
<p>图片里面提到了三种不同的 coupling：</p>
<ol>
<li>Thermal Coupling: $-TS$</li>
<li>Mechanical Coupling: $-YX$</li>
<li>Chemical Coupling: $-\sum_\mu_i N_i$</li>
</ol>
<p>其中 $Y$ 是广义力（例如压强 $p$ ），$X$ 是广义位移（例如体积 $V$ ）<sup id="fnref-6266-1"><a href="#fn-6266-1" rel="footnote">1</a></sup>。这个也不需要很多解释吧，深刻的解释我也没用，总之，顾名思义。</p>
<h2>图片的诠释</h2>
<p>现在可以开始解释图片的意思了。首先解释各个符号的意思：</p>
<ol>
<li>$U$, $H$, $A$, $G$, $\Omega$ 分别是：内能，焓，Helmholtz 自由能，Gibbs 自由能，巨热力学势。</li>
<li>{$S$, $T$}， {$X$, $Y$}， {$&#123;N_i&#125;,&#123;\mu_i&#125;$} 分别是：{熵，温度}，{广义位移，广义力}， {粒子数，化学势}。</li>
<li>三种 coupling 上面已经解释了。</li>
</ol>
<p>整个图片是从中间的 $U(S,X,&#123;N_i&#125;)$ 开始的，这是内能，内能是熵S、广义位移 X （以及粒子分布 {N_i} ）的函数。。</p>
<ol>
<li>如果我们给内能 $U(S, X, &#123;N_i&#125;)$ 加上一个 mechanical coupling $-XY$，那么就得到了焓。从前面的 Legendre transformation 看到，这时候焓 $H$ 变成了 $S, X, &#123;N_i&#125;$ 的函数。所以在气体的理论中，$H$ 是 $S, p$ 的函数，所以等压热容自然是 $C_p = \left( \partial_T H\right)_p$. </li>
<li>如果我们给内能和焓加上 thermal coupling $-ST$，那么我们就得到了两种自由能，分别是 Helmholtz 自由能和 Gibbs 自由能。同第一条里的道理，可以通过 Legendre transformation 自行分析两个是什么的函数。</li>
<li>如果我们给 Helmholtz 自由能加上一个 chemical coupling $-\sum_i \mu_i N_i$，那么我们得到了巨热力学势 $\Omega(T,X,&#123;\mu_i&#125;)$。</li>
</ol>
<p>至于物理意义，从图上也很明确。例如焓 H 是内能去掉 mechanical coupling，也就是说，焓在不考虑机械功的时候好用，例如焓在考虑其他体积不变的时候好用，因为这时候吸热就是焓。其他的也是同样的方式理解。这样我们<strong>仅仅通过内能 $U(S, X, &#123;N_i&#125;)$ 和 Legendre transformation 就可以获得其他的热力学势</strong>。</p>
<h3>Maxwell 关系</h3>
<p>内能 $U(S,X,N)$ 出发，根据不同的 coupling，我们可以导出不同的热力学势是什么的函数（也可以通过 Legendre transformation，这里简单起见只利用图片来做）。例如，H 是什么的函数？$U(S,X,N)$ 我们去掉了 mechanical coupling -YX 那么 得到的 H 就是 $H(S,Y,N)$，因为勒让德变换 $H = U &#8211; YX$ ，原来是变量 X 的函数，要变成 Y  的函数。</p>
<p>我们知道了这些函数的自变量是什么，下一步就可以写出所有的热力学势的微分式。只举一个例子：</p>
<p>$$\mathrm d U(S, X) = T\mathrm d S + Y \mathrm d X $$</p>
<p>然后，我们可以写出这些热力学势的全微分（由偏微分表示的，就是 chain rule）。同样只举一个例子：</p>
<p>$$\mathrm dU(S, X) = \left(\frac{\partial U}{\partial S}\right)_X \mathrm d S + \left(\frac{\partial U}{\partial X}\right)_S \mathrm X$$</p>
<p>对比上面两个公式，可以得到两个式子，分别是</p>
<p>$$T = \left(\frac{\partial U}{\partial S}\right)_X $$</p>
<p>$$Y =  \left(\frac{\partial U}{\partial X}\right)_S$$</p>
<p><strong>用同样的方法得到由另外的热力学势表达的 $T$ 和 $Y$，这样就可以获得一组 Maxwell 关系式。然后用类似的方法处理所有的热力学势，就可以获得全部的 Maxwell 关系。</strong></p>
<p><strong>另外，我们看到热力学量可以通过对相应的热力学势求偏微分来获得，很方便。</strong></p>
<p>这个推导在物理中很常见，例如电动力学的学习中，磁场能的导出也是用类似的手段。</p>
<h2>Legendre Transformation Revisited</h2>
<p>上面除了图片有点物理之外，就是数学了，或者说就是 Legendre transformaton 了。一开始那个 Legendre transformation 看起来就是硬生生的代数呢，感觉并没有什么直观的意义？其实这个 transformation 背后有很多可以挖掘的，包括我们喜欢的简洁明了的图像。</p>
<p>我们换种方式来找出函数 $f(x)$ 的 Legendre 变换。</p>
<ol>
<li>把函数在 x-y 坐标系中画出来（蓝色的实线）。</li>
<li>做一条直线 $y=px$ . </li>
<li>我们现在可以定义一个距离，也就是做一条垂直 x 轴的直线，在 $y=px$ 和 $f(x)$ 上的两个交点的距离： $F(x,p) = xp &#8211; f(x)$. 现在看起来已经有了 Legendre transformation 的样子了。但是有个问题，这里 x 和 p 是两个独立的变量。</li>
<li>Legendre transformation 要求在给定一个直线斜率 p 之后，这个距离 $F(x,p)$ 最大。这样就确定了 x 和 p  的关系。也就是说要求 $\frac{\partial F(x,p)}{\partial x} = 0$，简化之后，$f'(x)=p$。如图所示。</li>
<li>这样把 x 和 p 的关系 $x(p)$ 代入 $F(x,p)$ 中，我们的距离就变成单单 p 的函数，$F(p)$ 。这就是 $f(x)$ 的 Legendre transformation.</li>
</ol>
<p><a href="http://multiverse.lamost.org/blog/wp-content/uploads/2014/02/legendreTransformation.png"><img src="http://multiverse.lamost.org/blog/wp-content/uploads/2014/02/legendreTransformation.png" alt="legendreTransformation" width="390" height="256" class="aligncenter size-full wp-image-6503" /></a></p>
<p>这里面的几何关系就是，$p$ 是斜率，$f'(x)$ 也是斜率。</p>
<p>说到这里还不够清楚，那么我们重写一下这个关系：</p>
<p>$$F(p) + f(x) = xp$$</p>
<p>嗯？非常简单粗暴：$f(x)$ 和 $F(p)$ 具有对称性。等一下，这个关系联想到了什么？我们把上图中的表示切线的点划线延长出来，</p>
<p><a href="http://multiverse.lamost.org/blog/wp-content/uploads/2014/02/abcdefghi.png"><img src="http://multiverse.lamost.org/blog/wp-content/uploads/2014/02/abcdefghi.png" alt="abcdefghi" width="546" height="386" class="aligncenter size-full wp-image-6504" /></a></p>
<p>从这个图上，明显的就是斜率 p 乘以 x 得到了 $f(x) + F(p)$，即</p>
<p>$$f(x)+F(p)=p x$$</p>
<p>简单明了吧。这就是 f(x) 和 F(p) 之间的 Legendre transformation .明显的这个变换具有对称性，因为 f(x) 和 F(p ) 的地位相同。</p>
<p>至于更多的关于这个变换的内容，可以参考<a href="http://book.douban.com/subject/1728598/">《经典力学的数学方法》</a>这本书，或者<a href="http://arxiv.org/abs/0806.1147">这篇文献</a>。这是物理上一个非常核心的变换，对于整个物理体系有很重要的作用。</p>
<h2>微分几何</h2>
<p>上面的这些东西，是我们本科学习的，我们会觉得好乱！是的，好乱！那是因为我们使用的数学语言很含糊。我们为什么要说一个量是什么什么的函数？因为我们想要求导数。</p>
<p>如果我们有一种方法，可以得到导数的含义，但是不需要指定一个量是什么什么的函数，那么上面的这些混乱就没有了。是的，这种方法就是外微分。</p>
<p>至于具体怎么理解这个问题，可以读一下这篇文章：http://www.av8n.com/physics/thermo-forms.htm</p>
<div class="footnotes">
<hr />
<ol>
<li id="fn-6266-1">
如果不熟悉广义力的话，这里解释一下，以免后面犯错。因为我们常常讨论系统的能量的增量，所以广义力的通过外界对系统做工来定义的。我们说外界对系统做了功 $\mathrm W = Y \mathrm d X$，这里面就是广义力乘以广义位移，自然就是外界对系统做的功了。需要注意的是，由于我们是说的<strong>外界对系统做功</strong>，所以这个力方向是指向系统的，而不是指向外部的。所以在气体的例子里面 $\mathrm dW = -p \mathrm dV$，广义力是指的 $-p$. 当然，暗能量/ quinessence 这种奇葩的存在，我们先不讨论。&#160;<a href="#fnref-6266-1" rev="footnote">&#8617;</a>
</li>
</ol>
</div>
<div class='yarpp-related-rss'>
<hr /><p><big><strong><font color="#ff6600">长程相关文章:</font></strong></big></p><ol>
<li><a href="http://multiverse.lamost.org/blog/6250" rel="bookmark" title="心理叠加态：从量子爱情到人的所有心理">心理叠加态：从量子爱情到人的所有心理 </a><hr /></li>
<li><a href="http://multiverse.lamost.org/blog/2292" rel="bookmark" title="Relativistic Thermal Dynamics | 相对论性热力学">Relativistic Thermal Dynamics | 相对论性热力学 </a><hr /></li>
<li><a href="http://multiverse.lamost.org/blog/2284" rel="bookmark" title="How to construct the metric tensor?">How to construct the metric tensor? </a><hr /></li>
</ol></p>
</div>
]]></content:encoded>
			<wfw:commentRss>http://multiverse.lamost.org/blog/6266/feed</wfw:commentRss>
		<slash:comments>0</slash:comments>
		</item>
		<item>
		<title>心理叠加态：从量子爱情到人的所有心理</title>
		<link>http://multiverse.lamost.org/blog/6250</link>
		<comments>http://multiverse.lamost.org/blog/6250#comments</comments>
		<pubDate>Sun, 16 Feb 2014 07:54:38 +0000</pubDate>
		<dc:creator><![CDATA[时见疏星]]></dc:creator>
				<category><![CDATA[万物皆循因果]]></category>
		<category><![CDATA[Statistical Physics]]></category>
		<category><![CDATA[Statistics]]></category>
		<category><![CDATA[心理学]]></category>
		<category><![CDATA[爱情]]></category>
		<category><![CDATA[物理]]></category>
		<category><![CDATA[疯狂的科学]]></category>

		<guid isPermaLink="false">http://multiverse.lamost.org/blog/?p=6250</guid>
		<description><![CDATA[$$\newcommand{\bra}[1]{\left\langle #1\right&#124;} \newcommand{\ket}[1]{\left&#124; #1\right\rangle} \newcommand{\braket}[2]{\langle #1 \mid #2 \rangle} \newcommand{\avg}[1]{\left&#60; #1 \right>}$$ 系列文章目录： 第一篇：爱情的严格量子力学描述 第二篇：爱情的量子理论2 第三篇：心理叠加态：从量子爱情到人的所有心理 第四篇：基于统计数据的量子爱情 最近写了两篇关于用量子理论的方法来描述爱情的文章1，经过一些思考，我现在觉得我们可以把这个思路的核心概念提取出来，并且加以推广。如果我下面的整个想法是在重复造轮子，请见谅。我非常愿意学习理论心理学中类似的理论。我思考这个问题的初衷只是复习量子，但我对理论心理学所知极少，所有可能我的想法在理论心理学家那里会很幼稚而且极可能跟先前的理论重复。 我知道理论心理学有个分支叫做 Quantum Psychology，不过似乎是一种更加深层次理论，要解释从现实到心理的映射，我下面要说的是讨论用量子力学的方法来做唯像的心理学。 出发点：心理状态可以用态空间（一般为 Hilbert 空间）中的态来描述，这也就是说，这个空间中任意两个态的叠加也可以是人的心理状态，例如处在高兴和悲伤的叠加态等等。 之前所写的文章中的性格态，我很明确的提出了是心理性格。所以之前的模型中，无论是爱情状态和是性格状态，都是心理或者思维的状态。所以总的来说，我觉得有可能把爱情和性格可以叠加的想法推广到所有的心理状态都可以叠加，只要是我们所说的心理状态出在同一个态空间。所以这需要一种心理理论，把人的所有的心理或者性格分类，也就是说，要把人的完整心理分成不同的子空间，这些子空间的直和就可以组成整个心理。当然，具体的讨论中，不太可能讨论完整的心理，所以我们可以仅研究我们关心的一组子空间直和。 从提问题开始吧。 为什么量子的方法有效 第一个要问的问题是，为什么我们可以用类似量子力学的方法来描述心理状态呢？ 我们能这样做的原因是，心理状态常常并不是那么确定的，例如我们说一个人在做决定的时候，可能会犹豫，这就是说如果我们要在$&#92;{\ket{\mathrm{Yes}},\ket{\mathrm{No} } &#92;}$ 这样态空间基矢下面讨论问题，那么我们会发现犹豫的状态可以用这两个本征态的叠加来描述 $$C_1\ket{\mathrm{Yes}}+ C_2 \ket{\mathrm{No}} $$ 到底这个人倾向于回答是还是否，取决于两个系数的模（因为可能为复数）的大小。 当然，我们也可以找到一组更好的基矢，一般而言正交的基矢比较好用，例如对于这样一个心理状态 $$ \ket{\mathrm{Yes}}+...<div class='yarpp-related-rss'>
<hr />
<big><strong><font color="#ff6600">长程相关文章:</font></strong></big><ol>
<li><a href="http://multiverse.lamost.org/blog/6318" rel="bookmark" title="你我之上的幽灵">你我之上的幽灵 </a><hr /></li>
<li><a href="http://multiverse.lamost.org/blog/6229" rel="bookmark" title="爱情的量子理论2">爱情的量子理论2 </a><hr /></li>
<li><a href="http://multiverse.lamost.org/blog/593" rel="bookmark" title="A Brief Summary of Statistical Physics">A Brief Summary of Statistical Physics </a><hr /></li>
</ol>
</div>
]]></description>
				<content:encoded><![CDATA[
<p>$$\newcommand{\bra}[1]{\left\langle #1\right|}<br />
\newcommand{\ket}[1]{\left| #1\right\rangle}<br />
\newcommand{\braket}[2]{\langle #1 \mid #2 \rangle}<br />
\newcommand{\avg}[1]{\left&lt; #1 \right>}$$</p>
<p>系列文章目录：<br />
第一篇：<a href="http://multiverse.lamost.org/blog/6207">爱情的严格量子力学描述</a><br />
第二篇：<a href="http://multiverse.lamost.org/blog/6229">爱情的量子理论2</a><br />
第三篇：<a href="http://multiverse.lamost.org/blog/6250">心理叠加态：从量子爱情到人的所有心理</a><br />
第四篇：<a href="http://multiverse.lamost.org/blog/6328">基于统计数据的量子爱情</a></p>
<hr />
<p>最近写了两篇关于用量子理论的方法来描述爱情的文章<sup id="fnref-6250-0"><a href="#fn-6250-0" rel="footnote">1</a></sup>，经过一些思考，我现在觉得我们可以把这个思路的核心概念提取出来，并且加以推广。<strong>如果我下面的整个想法是在重复造轮子，请见谅。我非常愿意学习理论心理学中类似的理论。我思考这个问题的初衷只是复习量子，但我对理论心理学所知极少，所有可能我的想法在理论心理学家那里会很幼稚而且极可能跟先前的理论重复。</strong><br />
<span id="more-6250"></span><br />
我知道理论心理学有个分支叫做 Quantum Psychology，不过似乎是一种更加深层次理论，要解释从现实到心理的映射，我下面要说的是讨论用量子力学的方法来做唯像的心理学。</p>
<p><strong>出发点：心理状态可以用态空间（一般为 Hilbert 空间）中的态来描述，这也就是说，这个空间中任意两个态的叠加也可以是人的心理状态，例如处在高兴和悲伤的叠加态等等。</strong></p>
<p>之前所写的文章中的性格态，我很明确的提出了是心理性格。所以之前的模型中，无论是爱情状态和是性格状态，都是心理或者思维的状态。所以总的来说，我觉得<strong>有可能把爱情和性格可以叠加的想法推广到所有的心理状态都可以叠加，只要是我们所说的心理状态出在同一个态空间</strong>。所以这需要一种心理理论，把人的所有的心理或者性格分类，也就是说，<strong>要把人的完整心理分成不同的子空间，这些子空间的直和就可以组成整个心理</strong>。当然，具体的讨论中，不太可能讨论完整的心理，所以我们<strong>可以仅研究我们关心的一组子空间直和</strong>。</p>
<p>从提问题开始吧。</p>
<h2>为什么量子的方法有效</h2>
<p><strong>第一个要问的问题是，为什么我们可以用类似量子力学的方法来描述心理状态呢？</strong></p>
<p>我们能这样做的原因是，心理状态常常并不是那么确定的，例如我们说一个人在做决定的时候，可能会犹豫，这就是说如果我们要在$&#92;{\ket{\mathrm{Yes}},\ket{\mathrm{No} } &#92;}$ 这样态空间基矢下面讨论问题，那么我们会发现犹豫的状态可以用这两个本征态的叠加来描述</p>
<p>$$C_1\ket{\mathrm{Yes}}+ C_2 \ket{\mathrm{No}}  $$</p>
<p>到底这个人倾向于回答是还是否，取决于两个系数的模（因为可能为复数）的大小。</p>
<p>当然，我们也可以找到一组更好的基矢，一般而言正交的基矢比较好用，例如对于这样一个心理状态</p>
<p>$$ \ket{\mathrm{Yes}}+ \ket{\mathrm{No}}  $$</p>
<p>我们可以重新选取基矢 $&#92;{\ket{\psi_1}=\ket{\mathrm{Yes}}+\ket{\mathrm{No} },\ket{\psi_2} = \ket{\mathrm{Yes}}-\ket{\mathrm{No} } &#92;}$，然后心理状态就可以描述成</p>
<p>$$\ket{\mathrm{\psi_1}}$$</p>
<p>或者，甚至可能会出现像中微子那样的问题，就是类似味道本征态常常不是我们关心的本征态，质量本征态才是。或许 Yes 和 No 的本征态，并不是我们关心的本征态，或许中立本征态才是我们关心的，数学上就是刚刚举得例子。</p>
<h2>如何建立模型</h2>
<p><strong>第二个问题是，如果要建立一个比较完整的关于心理的模型，对心理状态的拆分有哪些要求呢？</strong></p>
<p>开始提到了，要把<strong>复杂心理空间</strong>（就是我们关心的所有的心理）拆分成可以独立演化的心理，这些元素化的心理就是元空间（似乎理论心理学中有类似的概念，心理学元理论？<sup id="fnref-6250-1"><a href="#fn-6250-1" rel="footnote">2</a></sup>），要求在我们所要研究的整个复杂心理空间是元空间的直积，这也是为什么随便起了个名字叫元空间，而不叫子空间的原因。</p>
<p>除此之外，在一般情况下似乎没有什么特殊的限制，甚至连不同的元空间中有相同的元素都没关系，不过可能会使得计算变得复杂。</p>
<p>更进一步，我们可以利用群论来讨论对称性，子群，陪集等等等等。这是一个非常非常深的坑坑。</p>
<h2>用于更大的人群样本——统计问题</h2>
<p><strong>之前用这种方法来描述爱情（哎，只是描述了而已，希望能更快的做出演化理论），可以用来描述单人体系或者二人体系，到了二人体系的结果的理解和解释有点困难了。如果我们用上统计的方法呢？例如我们处理一个人的一段时间内的平均心理，或者多次测量的平均心理，或者多人的平均心理（有点像系综理论）等等。</strong></p>
<p>一个公式来说，就是</p>
<p>$$ \avg{O} = \sum_i \rho_i \ket{\mathrm{ \psi_i }} $$</p>
<p>$\rho_i$ 是概率权重。只要找到这个量，所有的问题就解决了。</p>
<h2>能谱问题</h2>
<p>上面提到了统计，在物理中，我们会有能谱的概念，那么能谱这个概念可以借用过来么？</p>
<p>我们可以举个例子，例如我们把疼痛分成 0~10 级别，那么我们可以写下能谱，</p>
<table>
<thead>
<tr>
<th>所谓能量</th>
<th align="center">对应的态</th>
</tr>
</thead>
<tbody>
<tr>
<td>0</td>
<td align="center">$\ket{0}$</td>
</tr>
<tr>
<td>1</td>
<td align="center">$\ket{1}$</td>
</tr>
<tr>
<td>2</td>
<td align="center">$\ket{2}$</td>
</tr>
<tr>
<td>&#8230;</td>
<td align="center">&#8230;</td>
</tr>
<tr>
<td>10</td>
<td align="center">$\ket{10}$</td>
</tr>
</tbody>
</table>
<p>这样就可以建立类似物理中能谱的概念，但是，不同的是，通常这种能谱在统计中的体现，不是出现在 Boltzmann 因子中的，因为并不是这个数字越高，就越难出现，也不是数字越小，就越难出现。或者，如果想要用 Boltzmann 因子，那就要好好的定义一套关于态密度的理论。<sup id="fnref-6250-2"><a href="#fn-6250-2" rel="footnote">3</a></sup></p>
<h2>总之</h2>
<p>总之，大致看来，从心理叠加态这个假设出发来描述人的心理，是很可能行得通的。</p>
<div class="footnotes">
<hr />
<ol>
<li id="fn-6250-0">
<a href="http://multiverse.lamost.org/blog/6207">爱情的严格量子力学描述</a> 和 <a href="http://multiverse.lamost.org/blog/6229">爱情的量子理论2</a>&#160;<a href="#fnref-6250-0" rev="footnote">&#8617;</a>
</li>
<li id="fn-6250-1">
我并不知道，我对心理学知道的极少。&#160;<a href="#fnref-6250-1" rev="footnote">&#8617;</a>
</li>
<li id="fn-6250-2">
态密度是一个必须考虑的问题，记录一下。&#160;<a href="#fnref-6250-2" rev="footnote">&#8617;</a>
</li>
</ol>
</div>
<div class='yarpp-related-rss'>
<hr /><p><big><strong><font color="#ff6600">长程相关文章:</font></strong></big></p><ol>
<li><a href="http://multiverse.lamost.org/blog/6318" rel="bookmark" title="你我之上的幽灵">你我之上的幽灵 </a><hr /></li>
<li><a href="http://multiverse.lamost.org/blog/6229" rel="bookmark" title="爱情的量子理论2">爱情的量子理论2 </a><hr /></li>
<li><a href="http://multiverse.lamost.org/blog/593" rel="bookmark" title="A Brief Summary of Statistical Physics">A Brief Summary of Statistical Physics </a><hr /></li>
</ol></p>
</div>
]]></content:encoded>
			<wfw:commentRss>http://multiverse.lamost.org/blog/6250/feed</wfw:commentRss>
		<slash:comments>0</slash:comments>
		</item>
		<item>
		<title>豆瓣九点和博客访问量</title>
		<link>http://multiverse.lamost.org/blog/4730</link>
		<comments>http://multiverse.lamost.org/blog/4730#comments</comments>
		<pubDate>Tue, 11 Dec 2012 02:39:03 +0000</pubDate>
		<dc:creator><![CDATA[时见疏星]]></dc:creator>
				<category><![CDATA[万物皆循因果]]></category>
		<category><![CDATA[Blogging]]></category>
		<category><![CDATA[Data Visualization]]></category>
		<category><![CDATA[Statistics]]></category>
		<category><![CDATA[Visualizing Data]]></category>
		<category><![CDATA[豆瓣]]></category>

		<guid isPermaLink="false">http://multiverse.lamost.org/blog/?p=4730</guid>
		<description><![CDATA[到现在为止，我的博文两次上了豆瓣九点科技，所以我有两份豆瓣九点带来访客的数据。既然有了数据，那自然要利用一下。 两次分别是 2011 年 8 月 4 日到 8 月 8 日和 2012 年 12 月 8 日到 12 月 11 日（尚未完全完成）。 数据分别是 multiverse-20110804-20110808.csv：2011 年 8 月 multiverse-20121208-20121211.csv：2012 年 12 月 利用 Mathematica，把数据按照时间绘制出来。不过比较忙，所以只处理 Total Visitors 和 Unique Visitors 的数据。 （右侧是...<div class='yarpp-related-rss'>
<hr />
<big><strong><font color="#ff6600">长程相关文章:</font></strong></big><ol>
<li><a href="http://multiverse.lamost.org/blog/6250" rel="bookmark" title="心理叠加态：从量子爱情到人的所有心理">心理叠加态：从量子爱情到人的所有心理 </a><hr /></li>
<li><a href="http://multiverse.lamost.org/blog/5748" rel="bookmark" title="我们的征途——系外行星">我们的征途——系外行星 </a><hr /></li>
<li><a href="http://multiverse.lamost.org/blog/4648" rel="bookmark" title="数据可视化">数据可视化 </a><hr /></li>
</ol>
</div>
]]></description>
				<content:encoded><![CDATA[<p>到现在为止，我的博文两次上了豆瓣九点科技，所以我有两份豆瓣九点带来访客的数据。既然有了数据，那自然要利用一下。</p>
<p>两次分别是 2011 年 8 月 4 日到 8 月 8 日和 2012 年 12 月 8 日到 12 月 11 日（尚未完全完成）。</p>
<p>数据分别是</p>
<p style="margin:5px 15px 5px 20px;border:1px solid #7aca29;padding:2px 5px 2px 5px;">
<a href='http://multiverse.lamost.org/blog/wp-content/uploads/2012/12/multiverse-20110804-20110808.csv'>multiverse-20110804-20110808.csv：2011 年 8 月</a><br />
<br />
<a href='http://multiverse.lamost.org/blog/wp-content/uploads/2012/12/multiverse-20121208-20121211.csv'>multiverse-20121208-20121211.csv：2012 年 12 月</a>
</p>
<p>利用 Mathematica，把数据按照时间绘制出来。不过比较忙，所以只处理 Total Visitors 和 Unique Visitors 的数据。<span id="more-4730"></span></p>
<p><a href="http://multiverse.lamost.org/blog/wp-content/uploads/2012/12/WebsiteVistors.jpg"><img src="http://multiverse.lamost.org/blog/wp-content/uploads/2012/12/WebsiteVistors.jpg" alt="" title="2011 年 8 月" width="600" height="390" class="aligncenter size-full wp-image-4734" /></a></p>
<p><a href="http://multiverse.lamost.org/blog/wp-content/uploads/2012/12/WebsiteVistors2.jpg"><img src="http://multiverse.lamost.org/blog/wp-content/uploads/2012/12/WebsiteVistors2.jpg" alt="" title="2012 年 12 月" width="600" height="393" class="aligncenter size-full wp-image-4735" /></a></p>
<p><img src="http://multiverse.lamost.org/blog/wp-content/uploads/2012/12/bar.jpg" alt="" title="bar" width="7" style="float:right;" /></p>
<p>（右侧是 BrightBands 色带，向上指数据大，向下指数据小。）=></p>
<p>上图是去年的数据，下图是今年的数据。</p>
<p>为了更加直观，添加了 Hue 的背景，用不同的颜色来区分一天中不同的小时。同时为了能够更好地提取出具有差不多访问者的小时时刻，使用 BrightBands 色带来填满数据点和时间轴（对于大量数据更有效些）。</p>
<p>首先说明的是，我用的是 Pacific Time，但是从 GA 得知绝大多数用户（由于高达 85% 以上）来自国内，因此要把时间换算成北京时间，即 +16 小时，而对于去年那次，由于夏令时缘故，需 +15 小时。由于图表我另有用途，所以并不切换到北京时间，但是下文所讲的白天黑夜是北京时间。</p>
<p>这样的话，可以用一幅图来展示代表小时的颜色的意义：</p>
<p><a href="http://multiverse.lamost.org/blog/wp-content/uploads/2012/12/NightDay.jpg"><img src="http://multiverse.lamost.org/blog/wp-content/uploads/2012/12/NightDay.jpg" alt="" title="NightDay" width="600" height="386" class="aligncenter size-full wp-image-4762" /></a></p>
<p>上图中的连续色带用来表示白天黑夜，可见绿线附近是白天，而紫色粉色附近是黑夜。</p>
<p>有了这些铺垫之后，可以很快发现，两张图的流量低谷恰在凌晨。哎，没有为我们提供新观点的可视化是没意义的。</p>
<p>需要提到，我两次都是凌晨写的文章。但两次数据表明</p>
<ul>
<li>大规模的爆发皆为下午 14:00，15:00 左右。大约 9 小时（即深夜 12 点）后进入低谷，因为大家都睡觉去了。</li>
<li>上面提到国内访客大约 85%，也就是说国内/国外近似为 5.5，到了夜间，数据主要是紫色和红色。从上面的 BrightBands 色带可以看到橙色大约是红色的六倍，与定量数据是吻合的。</li>
<li>每天中可以看到 filling 的色带的间隔出现，比如绿色和浅蓝色的间隔出现，这是一天中访客波动造成的。这里颜色所代表的和曲线的走势相同，少量数据没有优势，但是对于大量数据的话，颜色的重复出现就更容易观察到。</li>
<li>完整的一天大约有五次峰值。大致为早上一次，午饭前一次，午饭后一次，下午一次，晚上两次。</li>
<li>作为上述五峰值现象的一个特殊情况，爆发第一天的时候，两次是惊人的相似。</li>
</ul>
<p>我这种绘图方法需要一定的了解之后才可以从中看到比较多的信息，所以不算是一种好的可视化。不过如果加上 interactive 的功能，那就好多了。</p>
<p>在绘图过程中，我还发现一个很奇怪的现象。我把 Total Visitors 和 Unique Visitors 都导出来，然后通过设置 filling 规则为：如果 Total Visitors 数量上多于 Unique Visitors，那么使用蓝色来 fill 两者之间的差异，反之，使用桔色。<br />
原则上来说，应该只有蓝色出现，但是实际情况却并非如此。看下图。</p>
<p><a href="http://multiverse.lamost.org/blog/wp-content/uploads/2012/12/WebsiteVistors3.jpg"><img src="http://multiverse.lamost.org/blog/wp-content/uploads/2012/12/WebsiteVistors3.jpg" alt="" title="WebsiteVistors3" width="600" height="390" class="aligncenter size-full wp-image-4736" /></a></p>
<p><a href="http://multiverse.lamost.org/blog/wp-content/uploads/2012/12/WebsiteVistors4.jpg"><img src="http://multiverse.lamost.org/blog/wp-content/uploads/2012/12/WebsiteVistors4.jpg" alt="" title="WebsiteVistors4" width="600" height="393" class="aligncenter size-full wp-image-4737" /></a></p>
<p>上图是去年的情况，下图是今年的情况。两者都有桔色出现。很好奇这是如何造成的。是统计不准确？还是我对两个概念理解有错？</p>
<p>当然了，上面提到了两次的相似性，那么我们就把两次的情况放在一起对照吧。</p>
<p><a href="http://multiverse.lamost.org/blog/wp-content/uploads/2012/12/WebsiteVistorsCompare.jpg"><img src="http://multiverse.lamost.org/blog/wp-content/uploads/2012/12/WebsiteVistorsCompare.jpg" alt="" title="WebsiteVistorsCompare" width="600" height="390" class="aligncenter size-full wp-image-4738" /></a></p>
<p>特别是第一天爆发的时候，两次很相似。为什么？是因为豆瓣本身的扩散方式的特点么？还是由于大家都是差不多在相同的时间工作累了让后开始豆瓣呢？抑或是统计次数太少，两次都是特殊情况？</p>
<p>最后，来两张传统的图记录一下吧。</p>
<p><a href="http://multiverse.lamost.org/blog/wp-content/uploads/2012/12/LastYear.jpg"><img src="http://multiverse.lamost.org/blog/wp-content/uploads/2012/12/LastYear.jpg" alt="" title="LastYear" width="600" height="390" class="aligncenter size-full wp-image-4789" /></a></p>
<p><a href="http://multiverse.lamost.org/blog/wp-content/uploads/2012/12/ThisYear1.jpg"><img src="http://multiverse.lamost.org/blog/wp-content/uploads/2012/12/ThisYear1.jpg" alt="" title="ThisYear" width="600" height="393" class="aligncenter size-full wp-image-4791" /></a></p>
<hr />
<p>代码以及本文所用图片和数据文件在此：</p>
<p style="margin:5px 15px 5px 20px;border:1px solid #7aca29;padding:2px 5px 2px 5px;">
<a href='http://multiverse.lamost.org/blog/wp-content/uploads/2012/12/Visualization.zip'>Visualization: 数据、Mathematica及图片</a>
</p>
<hr />
<p>关于作图的 post 都写完了，赶紧干正事吧~ 还要处理 BAO 的数据呢~</p>
<div class='yarpp-related-rss'>
<hr /><p><big><strong><font color="#ff6600">长程相关文章:</font></strong></big></p><ol>
<li><a href="http://multiverse.lamost.org/blog/6250" rel="bookmark" title="心理叠加态：从量子爱情到人的所有心理">心理叠加态：从量子爱情到人的所有心理 </a><hr /></li>
<li><a href="http://multiverse.lamost.org/blog/5748" rel="bookmark" title="我们的征途——系外行星">我们的征途——系外行星 </a><hr /></li>
<li><a href="http://multiverse.lamost.org/blog/4648" rel="bookmark" title="数据可视化">数据可视化 </a><hr /></li>
</ol></p>
</div>
]]></content:encoded>
			<wfw:commentRss>http://multiverse.lamost.org/blog/4730/feed</wfw:commentRss>
		<slash:comments>2</slash:comments>
		</item>
		<item>
		<title>数据可视化</title>
		<link>http://multiverse.lamost.org/blog/4648</link>
		<comments>http://multiverse.lamost.org/blog/4648#comments</comments>
		<pubDate>Sat, 08 Dec 2012 22:00:51 +0000</pubDate>
		<dc:creator><![CDATA[时见疏星]]></dc:creator>
				<category><![CDATA[万物皆循因果]]></category>
		<category><![CDATA[Coding]]></category>
		<category><![CDATA[Statistics]]></category>
		<category><![CDATA[天文]]></category>
		<category><![CDATA[疯狂的科学]]></category>
		<category><![CDATA[网络]]></category>

		<guid isPermaLink="false">http://multiverse.lamost.org/blog/?p=4648</guid>
		<description><![CDATA[Data visualization 是一件很有趣的事情。最近在尝试处理数据，便顺手翻了翻 visualization 的进展，然后除了 IBM 大名鼎鼎的的 many-eyes ，还有一个比较好有意思的网站是 visualizing.org。 Visualizing.org 跟 many-eyes 很像，是一个社区形式的网站，用户可以注册然后上传，而且网站还有积累下来的很多数据供用户使用。 当然我不是为了介绍这个网站才写这篇 post 的，写 post 是一个记笔记的过程，如果我不能从中学到什么，就有点浪费时间了。下面进入正题，我尝试总结一下 visualization 的时候的几个可用的经验。 应该使用何种形式来表现数据 从 visualizing.org 的分类中提取出来的有用的形式包括（不过说实话这样分类并不是很好用） Chart Time series Map Flow Matrix Network Hierarchy Info-graphic 要可视化的数据可以分几类（我想的不全面，欢迎补充，共同学习） 有一系列对象，他们之间相互有关联。写成 &#92;(&#92;bf &#92;mathrm A &#92;leftrightarrow...<div class='yarpp-related-rss'>
<hr />
<big><strong><font color="#ff6600">长程相关文章:</font></strong></big><ol>
<li><a href="http://multiverse.lamost.org/blog/5503" rel="bookmark" title="PKM —— 个人知识管理">PKM —— 个人知识管理 </a><hr /></li>
<li><a href="http://multiverse.lamost.org/blog/2358" rel="bookmark" title="iAstro及其他">iAstro及其他 </a><hr /></li>
<li><a href="http://multiverse.lamost.org/blog/2336" rel="bookmark" title="GADGET-2安装">GADGET-2安装 </a><hr /></li>
</ol>
</div>
]]></description>
				<content:encoded><![CDATA[<p>Data visualization 是一件很有趣的事情。最近在尝试处理数据，便顺手翻了翻 visualization 的进展，然后除了 IBM 大名鼎鼎的的 <a href="http://many-eyes.com">many-eyes</a> ，还有一个比较好有意思的网站是 <a href="http://visualizing.org/about">visualizing.org</a>。 Visualizing.org 跟 many-eyes 很像，是一个社区形式的网站，用户可以注册然后上传，而且网站还有积累下来的很多数据供用户使用。<span id="more-4648"></span></p>
<p>当然我不是为了介绍这个网站才写这篇 post 的，写 post 是一个记笔记的过程，如果我不能从中学到什么，就有点浪费时间了。下面进入正题，我尝试总结一下 visualization 的时候的几个可用的经验。</p>
<h2>应该使用何种形式来表现数据</h2>
<p>从 visualizing.org 的分类中提取出来的有用的形式包括（不过说实话这样分类并不是很好用）</p>
<ol>
<li>Chart</li>
<li>Time series</li>
<li>Map</li>
<li>Flow</li>
<li>Matrix</li>
<li>Network</li>
<li>Hierarchy</li>
<li>Info-graphic</li>
</ol>
<p>要可视化的数据可以分几类（我想的不全面，欢迎补充，共同学习）</p>
<ul>
<li><strong>有一系列对象，他们之间相互有关联。</strong>写成 &#92;(&#92;bf &#92;mathrm A &#92;leftrightarrow &#92;mathrm B&#92;) 粗体的拉丁字母表示一系列对象，比如一系列地点。</li>
</ul>
<p>这种情况下因为要展示数据之间相互关系，所以实质上是一个 network 图，不过通过一些技巧可以把简单的 network 图变成更好的形式。</p>
<p>方式一：使用转换成 flow 图。通过把对象列出两遍来是的原本应该是一个比较复杂难以看清的 network 变成了清晰易查找的 flow。</p>
<p>这类图中我喜欢的一个是 <a href="http://www.visualizing.org/visualizations/peoplemovin">people moving 的 flow</a><br />
<a href="http://multiverse.lamost.org/blog/wp-content/uploads/2012/12/peoplemigrate.png"><img src="http://multiverse.lamost.org/blog/wp-content/uploads/2012/12/peoplemigrate.png" alt="" title="peoplemigrate" width="550" /></a></p>
<p>这个 flow 图非常好的展示了从一个国家移民到另一个国家，上面的截图就是人们移居（migrate，是移民么？）到加拿大的情况，可以看到中国（CH）移民到加拿大的还是比较多的。通过这样的 flow，我们可以很容易很直观的分析数据。</p>
<p>方式二：圈形的 network 图。为什么要做出圈形呢？因为圈形可以使得连线集中在圈内部，而且可以减少数据交叉。通过 interactive design，可以使得连线无交叉。比如这个 <a href="http://www.visualizing.org/full-screen/27446">Migrants moving money</a>：</p>
<p><a href="http://multiverse.lamost.org/blog/wp-content/uploads/2012/12/migrationmoney.jpg"><img src="http://multiverse.lamost.org/blog/wp-content/uploads/2012/12/migrationmoney.jpg" alt="" title="migrationmoney" width="550" /></a></p>
<p>这个截图是中国的侨款，也就是中国移民所寄回祖国中国的钱数。可以看排除香港地区，美国是最大的来源。</p>
<p>事实上这种方法与第一种本质是相同的。</p>
<p>方式三：network 图。通过点和连线来关联。例子比如<a href="http://www.visualizing.org/full-screen/6252">Attractions of Councils: WEF GAC interlink survey</a></p>
<p><a href="http://multiverse.lamost.org/blog/wp-content/uploads/2012/12/AttractionsOfCouncils.jpg"><img src="http://multiverse.lamost.org/blog/wp-content/uploads/2012/12/AttractionsOfCouncils.jpg" alt="" title="AttractionsOfCouncils" width="878" /></a></p>
<p>但是这个图实际上并不好。而且有时候，线条是可以去掉的，比如这个<a href="http://www.visualizing.org/full-screen/44533">国际航班的可视化</a>：</p>
<blockquote><p>    Click a nation to see all connected nations via flights. Click again to see arranged nations based on the distance.<br />
    Double-click the background to reset.
</p></blockquote>
<p>截图：<br />
<img src="http://multiverse.lamost.org/blog/wp-content/uploads/2012/12/internantialflights.jpg" alt="" title="internantialflights" width="550" /></p>
<p>方式四：使用 table。不过为了更直观，使用面积等方式来代表数据的大小。</p>
<p>比如 10 个人任意两个人之间相互按照对对方的好感程度打分，为了展示任意两个人 A 和 B 之间相互的好感程度，可以使用颜色柱来展示，选定一个作为两个人好感程度相同，颜色柱之上的颜色表示 A 对 B 的好感大于 B 对 A 的好感，反之亦然。</p>
<p>这里有个 <a href="http://www.visualizing.org/full-screen/6407">council 之间的例子</a>，截图如下：</p>
<p><a href="http://multiverse.lamost.org/blog/wp-content/uploads/2012/12/colordimension.jpg"><img src="http://multiverse.lamost.org/blog/wp-content/uploads/2012/12/colordimension.jpg" alt="" title="colordimension" width="550" /></a></p>
<ul>
<li><strong>层级数据，数据之间可以分成几个层级关系。</strong></li>
</ul>
<p>就是 Hierarchy 图，不过有时候可以省掉连线。</p>
<p>比如这个 <a href="http://www.visualizing.org/full-screen/1047">soft drink 的 hierarchy 图</a></p>
<p><a href="http://multiverse.lamost.org/blog/wp-content/uploads/2012/12/softdrinks.png"><img src="http://multiverse.lamost.org/blog/wp-content/uploads/2012/12/softdrinks.png" alt="" title="softdrinks" width="550"  /></a></p>
<p>从这张截图立刻可以看到 coca-cola 和 pepsi 的庞大，通过原网页可以自由的放大缩小来查看不同的公司的产品。</p>
<p>这样的 hierarchy 图要比单调的并列的整整齐齐的列举要包含了更多的信息，因为圆圈的大小可以表示数据的一个维度，甚至还可以引入颜色等等来表示更多的维度。</p>
<ul>
<li><strong>简单的两维数据，比如某种现象出现的频数。</strong></li>
</ul>
<p>方式一：使用 Histogram。这是比较经典的选择，即使用矩形或者线条的长度来表示数据的大小。例如<a href="http://www.visualizing.org/full-screen/37008">这个关于能源的 visualization</a>，截图如下：<br />
<img src="http://multiverse.lamost.org/blog/wp-content/uploads/2012/12/HistogramViral.jpg"  width="438" height="556" /></p>
<p>方式二：使用树图（Tree map），使用面积表示数据的大小。这里有个 <a href="http://www.visualizing.org/full-screen/29356">UN 的 Global Pulse Visualization 的例子</a>：</p>
<p><a href="http://multiverse.lamost.org/blog/wp-content/uploads/2012/12/UNGlobalPulseVisualization.png"><img src="http://multiverse.lamost.org/blog/wp-content/uploads/2012/12/UNGlobalPulseVisualization.png" alt="" title="UNGlobalPulseVisualization" width="550" /></a></p>
<p>方式三：使用散点，使用散点的大小或者颜色等属性来表示数据的大小。</p>
<p>一个很优秀的例子是<a href="http://www.visualizing.org/full-screen/31071">学生坐座位习惯的例子</a>，截图：<br />
<a href="http://multiverse.lamost.org/blog/wp-content/uploads/2012/12/classroomhabit.jpg"><img src="http://multiverse.lamost.org/blog/wp-content/uploads/2012/12/classroomhabit.jpg" alt="" title="classroomhabit" width="550" /></a></p>
<p>事实上 tag page 也是属于这类，我们可以通过每个 tag 的大小颜色等等来标示数据的大小。</p>
<ul>
<li><strong>坐标数据</strong></li>
</ul>
<p>除了可以使用上面说提到的方式，对于坐标数据，有个特点是可以绘制地图（Map），而 Map 可以与其他形式结合，比如 flow。一个比较好的例子是<a href="http://www.visualizing.org/full-screen/44503">关于我们坐飞机的一张图</a>，截图如下：</p>
<p><a href="http://multiverse.lamost.org/blog/wp-content/uploads/2012/12/takeflight-000265.png"><img src="http://multiverse.lamost.org/blog/wp-content/uploads/2012/12/takeflight-000265.png" alt="" title="takeflight-000265" width="550" /></a></p>
<p>图片上部的地图是飞行的出发城市，下部的地图是终点城市。更多内容可以查看<a href="http://mat.ucsb.edu/qian/VizMarathon/vizMar.html">UCSB的这个站点</a>，其中提供了 demo 软件。</p>
<h2>不同 visualization 的结合</h2>
<p>前些时候，一位天文学家 Goodman 写过一篇关于<a href="http://arxiv.org/abs/1205.4747">高维天文数据可视化的论文</a>，其中提到了 linked views 很重要，就是说我们要多种可视化方式联合起来展示数据，我截取论文中一张图片来说明。</p>
<p><img src="http://multiverse.lamost.org/blog/wp-content/uploads/2012/12/linkedviews.jpg" alt="" title="Linked Views in Data Visualization" width="327" /></p>
<p>不同的 visualization 结合起来对数据进行多角度的呈现，可以使我们对数据有更深刻的理解。所以 data mining 实际上是一个应用非常广泛的专业，一个 data mining 专业的学生在现在这种天文专业被大量数据所轰炸（有篇论文甚至说是 data tsunami）的时代真是个宝贝啊。</p>
<p>有一个不错的历史方面的数据可视化例子，把时间线和地图集合起来展示的，这个方案实际是一种深层次的 linked views：<br />
<a href="http://www.conflicthistory.com/">Conflict History of the World</a></p>
<h2>一些有用的工具</h2>
<ol>
<li><a href="http://en.wikipedia.org/wiki/Data_visualization">http://en.wikipedia.org/wiki/Data_visualization</a><br />
自然要先查看一下 wikipedia 啦啦啦~</li>
<li>visualizing.org 有个列表：<br />
<a href="http://multiverse.lamost.org/blog/wp-content/uploads/2012/12/tools.jpg"><img src="http://multiverse.lamost.org/blog/wp-content/uploads/2012/12/tools.jpg" alt="" title="tools" width="500" /></a></li>
<li><a href="http://selection.datavisualization.ch/">http://selection.datavisualization.ch/</a> 列举了很多有用的工具。</li>
<li><a href="https://github.com/blprnt/Kepler-Visualization">https://github.com/blprnt/Kepler-Visualization</a> This is a Processing sketch to visualize data from NASA&#8217;s Kepler mission.</li>
<li><a href="http://flowingmedia.com/timeflow.html">http://flowingmedia.com/timeflow.html</a> Time Flow is an open-source timeline built to help journalists analyze temporal data. The application offers several view modes&#8211;timelime, calendar, list, table&#8211;to help explore thousands of data points. </li>
<li><a href="http://mapbox.com/">http://mapbox.com/</a><br />
Mapbox is a tool for map making.</li>
</ol>
<h2>Data Visualization 的机构/组织/社区</h2>
<ul>
<li><a href="http://envisioningtech.com/">http://envisioningtech.com/</a></li>
</ul>
<p>有些不错的 data visualization，比如（图片来自 envisioningtech.com）<br />
<a href="http://multiverse.lamost.org/blog/wp-content/uploads/2012/12/envisioningtech.png"><img src="http://multiverse.lamost.org/blog/wp-content/uploads/2012/12/envisioningtech.png" alt="" title="envisioning tech" width="550" /></a></p>
<ul>
<li>IBM 的 Many-eyes.com </li>
</ul>
<p>这个一开始提到了，是个 visualization 的社区。</p>
<ul>
<li><a href="http://datavisualization.ch/">http://datavisualization.ch/</a></li>
</ul>
<p>之前提到过它的工具列表了。这个网站是</p>
<blockquote><p>Datavisualization.ch is the premier news and knowledge resource for data visualization and infographics.</p></blockquote>
<ul>
<li><a href="http://visual.ly/">http://visual.ly/</a></li>
</ul>
<p>一个类似 data visualization 社区的网站。</p>
<ul>
<li><a href="http://visualization.geblogs.com/">http://visualization.geblogs.com/</a></li>
</ul>
<p>来自 GE 的例子。</p>
<ul>
<li><a href="http://oicweave.org/">http://oicweave.org/</a></li>
</ul>
<p>Web-based Analysis and Visualization Environment</p>
<hr />
<p>本文所用的数据按照 visualizing.org 所标示，使用 CC BY-NC-SA 协议，除了明确指明的图片，其他图片皆出自 visualizing.org。</p>
<p>好了讲完了，可以用 <a href="http://exoplanets.org/">exoplanets.org</a> 的数据来玩玩。</p>
<div class='yarpp-related-rss'>
<hr /><p><big><strong><font color="#ff6600">长程相关文章:</font></strong></big></p><ol>
<li><a href="http://multiverse.lamost.org/blog/5503" rel="bookmark" title="PKM —— 个人知识管理">PKM —— 个人知识管理 </a><hr /></li>
<li><a href="http://multiverse.lamost.org/blog/2358" rel="bookmark" title="iAstro及其他">iAstro及其他 </a><hr /></li>
<li><a href="http://multiverse.lamost.org/blog/2336" rel="bookmark" title="GADGET-2安装">GADGET-2安装 </a><hr /></li>
</ol></p>
</div>
]]></content:encoded>
			<wfw:commentRss>http://multiverse.lamost.org/blog/4648/feed</wfw:commentRss>
		<slash:comments>21</slash:comments>
		</item>
		<item>
		<title>宇宙学中的统计方法【丁】</title>
		<link>http://multiverse.lamost.org/blog/4389</link>
		<comments>http://multiverse.lamost.org/blog/4389#comments</comments>
		<pubDate>Thu, 06 Dec 2012 21:05:03 +0000</pubDate>
		<dc:creator><![CDATA[时见疏星]]></dc:creator>
				<category><![CDATA[天尽头的纸条]]></category>
		<category><![CDATA[Statistics]]></category>
		<category><![CDATA[宇宙学]]></category>
		<category><![CDATA[物理]]></category>

		<guid isPermaLink="false">http://multiverse.lamost.org/blog/?p=4389</guid>
		<description><![CDATA[宇宙学中的统计方法笔记系列，第四篇：likelihood 函数的计算方法，包括如何剔除没用的模式和如何找到 likelihood 的极值。 系列文章目录： 宇宙学中的统计方法【甲】 宇宙学中的统计方法【乙】 宇宙学中的统计方法【丙】 宇宙学中的统计方法【丁】 在 likelihood 方程里面是需要求解矩阵的逆（可参考CMB 的 likelihood 方程），而实际观测中数据量又极大，所有直接求逆会实际计算很慢，因此一种有效的求解 likelihood function 的方法是很重要的。 Modern Cosmology 里面举了一个具体的例子。 Karhunen-Loeve Techniques 这种方法的主要想法是，丢掉那么严重被噪声污染的模。比如我们发现有用的模只有10%，那么计算逆矩阵的话，计算量就减少到了原来的1/1000。但是如何找出那些有用的模呢？ 如果 covariance matrix 是对角的，我们之前在 【乙】 部分中提到对于对角化的 covariance matrix，我们可以得到 &#92;(C_S/C_N&#92;)，也就是信噪比。通过看信噪比的强弱，就可以知道那些模是有用的。可是真正的观测中，得到的数据的 covariance matrix 并不是对角化的，得到信噪比就比较困难。这正是 Karhunen-Loeve 方法所解决的问题。 现在假定我们有 &#92;(N_p&#92;)...<div class='yarpp-related-rss'>
<hr />
<big><strong><font color="#ff6600">长程相关文章:</font></strong></big><ol>
<li><a href="http://multiverse.lamost.org/blog/4364" rel="bookmark" title="宇宙学中的统计方法【丙】">宇宙学中的统计方法【丙】 </a><hr /></li>
<li><a href="http://multiverse.lamost.org/blog/2970" rel="bookmark" title="宇宙学中的统计方法【乙】">宇宙学中的统计方法【乙】 </a><hr /></li>
<li><a href="http://multiverse.lamost.org/blog/2918" rel="bookmark" title="宇宙学中的统计方法【甲】">宇宙学中的统计方法【甲】 </a><hr /></li>
</ol>
</div>
]]></description>
				<content:encoded><![CDATA[<p>宇宙学中的统计方法笔记系列，第四篇：likelihood 函数的计算方法，包括如何剔除没用的模式和如何找到 likelihood 的极值。<span id="more-4389"></span></p>

<p>系列文章目录：</p>
<ul>
<li><a href="http://multiverse.lamost.org/blog/2918">宇宙学中的统计方法【甲】</a></li>
<li><a href="http://multiverse.lamost.org/blog/2970">宇宙学中的统计方法【乙】</a></li>
<li><a href="http://multiverse.lamost.org/blog/4364">宇宙学中的统计方法【丙】</a></li>
<li><a href="http://multiverse.lamost.org/blog/4389">宇宙学中的统计方法【丁】</a></li>
</ul>
<hr />
<p>在 likelihood 方程里面是需要求解矩阵的逆（可参考<a href="http://multiverse.lamost.org/blog/2970#mjx-eqn-eqn-multipixellikelihood" target="_blank">CMB 的 likelihood 方程</a>），而实际观测中数据量又极大，所有直接求逆会实际计算很慢，因此一种有效的求解 likelihood function 的方法是很重要的。</p>
<p style="background:#f0ffff;margin:5px 15px 5px 20px;border:1px solid lightgreen;border-left:8px solid lightgreen;border-right:8px solid lightgreen;padding:2px 5px 2px 5px;">
<em>Modern Cosmology</em> 里面举了一个具体的例子。
</p>
<h2>Karhunen-Loeve Techniques</h2>
<p>这种方法的主要想法是，丢掉那么严重被噪声污染的模。比如我们发现有用的模只有10%，那么计算逆矩阵的话，计算量就减少到了原来的1/1000。但是如何找出那些有用的模呢？</p>
<p>如果 covariance matrix 是对角的，我们之前在 【乙】 部分中提到对于对角化的 covariance matrix，我们可以得到 &#92;(C_S/C_N&#92;)，也就是信噪比。通过看信噪比的强弱，就可以知道那些模是有用的。可是真正的观测中，得到的数据的 covariance matrix 并不是对角化的，得到信噪比就比较困难。这正是 Karhunen-Loeve 方法所解决的问题。</p>
<p>现在假定我们有 &#92;(N_p&#92;) 个数据点，&#92;(&#92;Delta_i&#92;)，与之前一样，这个数据点是由信号 &#92;(s_i&#92;) 和噪声 &#92;(n_i&#92;) 组成的。为了简单，我们假定信号和噪声是不关联的。</p>
<p>使用矩阵表达式，那么 covariance martrix 就可以写成<br />
&#92;[ {&#92;bf C} &#92;equiv &#92;langle &#92;Delta &#92;Delta^{T} &#92;rangle = {&#92;bf C_S} + {&#92;bf C_N} &#92;]</p>
<p>Karhunen-Loeve technique 是利用一系列矩阵变换把 noise covariance matrix 写成单位阵，然后 signal covariance matrix 写成对角形式，这样就可以比较信号和噪声了，当然我们用的数据矩阵也应该做相应的变换。比如我们把数据矩阵转动<br />
&#92;[ {&#92;bf &#92;Delta}&#8217; = {&#92;bf R} {&#92;bf &#92;Delta} &#92;]<br />
那么相应的 covariance matrix 也就变成了<br />
&#92;[ {&#92;bf C} = &#92;langle ({&#92;bf R &#92;Delta}) ({&#92;bf R &#92;Delta}) &#92;rangle ={&#92;bf R C R^{T}} &#92;]</p>
<p>如果 &#92;({&#92;bf C}’&#92;) 是个对角化的形式，那就好办了。所以，Karhunen-Loeve technique 的操作过程应该是：</p>
<ul>
<li>通过转动矩阵 &#92;({&#92;bf R_1} &#92;) 把 &#92;({&#92;bf C_N}&#92;) 对角化为 &#92;({&#92;bf C_N}&#8221;&#92;) ；</li>
<li>通过矩阵 &#92;({&#92;bf R_2}&#92;)把 &#92;({&#92;bf C_N}&#8221;&#92;) 化为单位阵：&#92;[ {&#92;bf C_N}&#8217; = {&#92;bf R_2 R_1 C_N R_1^T R_2^T}&#92;] 其实 &#92;(&#92;bf R_2&#92;) 是个对角阵，所以 &#92;({&#92;bf R_2^T} = {&#92;bf R_2} &#92;) ；</li>
<li>通过转动矩阵 &#92;({&#92;bf R_3}&#92;) 把进行过 &#92;({&#92;bf R_1}&#92;) 和 &#92;({&#92;bf R_2}&#92;) 操作的 &#92;({&#92;bf C_S}&#92;) 对角化为 &#92;({&#92;bf C_S}&#8217;&#92;) ：&#92;[{&#92;bf C_S}&#8217; = {&#92;bf R_3 R_2 R_1 C_S R_1^T R_2 R_3}&#92;]。同时 &#92;(&#92;bf C_N&#8217;&#92;) 也必须进行 &#92;(&#92;bf R_3&#92;) 操作，但是由于实对称矩阵的对角化通过 unitary 的矩阵来实现的（&#92;({&#92;bf R_3^{-1} = {&#92;bf R_3^T}}&#92;)），所以实际上再对 &#92;(&#92;bf C_N&#8217;&#92;) 进行 &#92;(&#92;bf R_3&#92;) 操作并不改变 &#92;(&#92;bf C_N&#8217;&#92;) 是单位阵的性质，因此这一步不需要任何计算；</li>
<li>对数据点进行相应的变换 &#92;[ {&#92;bf &#92;Delta&#8217;} = ( {&#92;bf R_3 R_2 R_1 } ){&#92;bf &#92;Delta} &#92;]</li>
</ul>
<p>这样变换之后，我们最终拿到的 covariance matrix 是<br />
&#92;begin{equation}<br />
{&#92;bf C}‘ &#92;equiv &#92;langle {&#92;bf &#92;Delta&#8217;&#92;Delta&#8217;^T } &#92;rangle =  {&#92;bf C_N&#8217;} + {&#92;bf C_S&#8217;} = {&#92;bf I} + {&#92;bf C_S&#8217;}<br />
&#92;end{equation}</p>
<p>通过判断 &#92;(&#92;bf C_S&#8217;&#92;) 的元素（只有对角元）与 1 的大小，可以判断某个模式是否应该舍弃。</p>
<p style="background:#f0ffff;margin:5px 15px 5px 20px;border:1px solid lightgreen;border-left:8px solid lightgreen;border-right:8px solid lightgreen;padding:2px 5px 2px 5px;">
<em>Modern Cosmology</em> P 356 有一个数据矩阵只有两个元素的例子。
</p>
<p>Karhunen-Loeve 方法已经有了很重要的应用。下图是 Bunn 和 Bond 用 K L techniques 重分析 COBE 卫星数据的几个图（<em>Modern Cosmology</em> P360）</p>
<p><img src="http://multiverse.lamost.org/blog/wp-content/uploads/2012/12/KLTechniques.jpg" alt="" title="KL Techniques" width="550" /></p>
<p>图中左上是 signal to noise (S/N) 最大的模式，而右下是 S/N 最小的模式。实际上左上角主要是 quadrupole 的贡献，右下角的图主要是小尺度观测的贡献。</p>
<p>下图是 K L techniques 用在 galaxy survey 上面的情况（Vogeley 和 Szalay，1996）。（<em>Modern Cosmology</em> P361）</p>
<p><img src="http://multiverse.lamost.org/blog/wp-content/uploads/2012/12/KLTechniques-GalaxySurvey.jpg" alt="" title="KLTechniques-GalaxySurvey" width="550" /></p>
<p>上图中展示的是 12 个有最大 S/N 的模式，都是大尺度的模。也就是说 K L techniques 恰好吧 galaxy survey 中的大尺度的数据筛选出来了。</p>
<p>Karhunen-Loeve technique 的另外一个很重要的用途是进行自洽性分析。<em>Modern Cosmology</em> P360 给了一个 the Python experiment 的例子。由于数据点太多，不方便直接检查数据的自洽性。于是他们使用 Karhunen-Loeve technique 把大 S/N 的数据挑出来，然后看看是不是跟观测数据所做的基本的概率假定相符，比如这里数据应该是 Gaussian 的，但是 the Python experiment 小组 第一次所用的 noise covariance matrix 导致筛选出来的这些结果并不是 Gaussian 的，于是他们就用新的 noise covariance matrix 重新做了分析。（具体例子分析请翻阅 <em>Modern Cosmology</em> P360）</p>
<p>在实际的观测中，这种方法并不是万能的，因为首先我们必须现有一个预设的 signal covariance matrix &#92;(&#92;bf C_S&#92;)，其次，这种方法在进行了上面的这么多的操作进行筛选数据点之后，还是需要按照原来的求解 likelihood 的方法来计算，也就是还是要求逆，虽然我们上面进行过了对角化，但是这只是一个特殊点进行的，也就是选择 &#92;(&#92;bf C_S&#92;) 是所定的点，这样在其他点，这些矩阵并不是对角化的，计算还是比较复杂。</p>
<h2>Optimal Quadratic Estimator</h2>
<p>上面的 K L techniques 还是要硬算 likelihood 的，而 optimal quadratic estimator 是一种不需要去完整的求解全局的 likehood 的方法。</p>
<p>Optimal quadratic estimator 是类似于 Newton 切线法求方程的根的方法，因为实际上我们要求解的量只是 likelihood 极大的时候的参数值，所以我们只需要找到如下方程的根就可以了，<br />
&#92;[ &#92;left.&#92;frac{&#92;partial &#92;scr L}{&#92;partial &#92;lambda} &#92;right| _ {&#92;lambda = &#92;bar &#92;lambda}= 0 &#92;]<br />
按照 Newton-Raphson 方法的想法，需要选定一个初始的参数空间的位置 &#92;(&#92;lambda^{(0)}&#92;)，因为对于多项式形式的函数这样的算法比较有优势，所以我们现在假定 likelihood 是 &#92;(&#92;bf C_S&#92;) 和 &#92;(&#92;bf C_N&#92;) 的 Gaussian 函数，那么我们对 likelihood 取 log 之后的式子就变成多项式形式了。这样我们把 &#92;(&#92;ln &#92;scr L&#92;) 在 &#92;(&#92;lambda^{(0)}&#92;) 附近展开</p>
<p>&#92;[<br />
(&#92;ln &#92;mathscr L) _{,&#92;lambda} (&#92;lambda) = (&#92;ln &#92;mathscr L) _{,&#92;lambda}(&#92;lambda^{(0)}) + (&#92;ln &#92;mathscr L) _{,&#92;lambda&#92;lambda}(&#92;lambda^{(0)}) ( &#92;lambda &#8211; &#92;lambda^{(0)}) &#92;]</p>
<p>只取前面的两项，并且把极值点真正的参数值 &#92;(&#92;hat &#92;lambda&#92;)带入，有 &#92;({&#92;ln&#92;scr L}_{,&#92;lambda} = 0&#92;)，即</p>
<p>&#92;[ &#92;hat&#92;lambda &#92;approx &#92;lambda^{(0)} &#8211; &#92;frac{ (&#92;ln &#92;scr L) _{,&#92;lambda}(&#92;lambda^{(0)}) }{(&#92;ln &#92;scr L) _{,&#92;lambda&#92;lambda}(&#92;lambda^{(0)})} &#92;]</p>
<p>实际上上式中所谓的 &#92;(&#92;hat &#92;lambda&#92;) 只是一个近似的准确值，因为我们只取了 Taylor 展开的前两项。但是通过迭代的方法，我们就可以无限趋近于真正的极值。</p>
<p>这种方法中出现了 likelihood 的导数。可以用 CMB 的情况作为例子来看看如何计算。对 CMB 来说<br />
&#92;[ (&#92;ln &#92;mathscr L) _{,&#92;lambda} = &#92;frac{&#92;partial}{&#92;partial &#92;lambda}&#92;left[ -&#92;frac{1}{2}&#92;ln(&#92;det C) &#8211; &#92;frac{1}{2} &#92;Delta C^{-1}&#92;Delta &#92;right]&#92;]</p>
<p>利用矩阵的一些计算技巧，&#92;(&#92;ln &#92;det(C) = &#92;mathrm{Tr} &#92;ln(C) &#92;) 和 &#92;( C_{,&#92;lambda}^{-1} = &#8211; C^{-1} C _ {,&#92;lambda} C^{-1} &#92;)<br />
&#92;begin{eqnarray}<br />
(&#92;ln &#92;mathscr L)_{,&#92;lambda} &amp;=&amp; &#92;frac{&#92;partial}{&#92;partial &#92;lambda}&#92;left[ -&#92;frac{1}{2}&#92;ln(&#92;det C) &#8211; &#92;frac{1}{2} &#92;Delta C^{-1}&#92;Delta &#92;right] &#92;nonumber &#92;&#92;<br />
&amp;=&amp; -&#92;frac{1}{2}&#92;frac{&#92;partial}{&#92;partial &#92;lambda} &#92;ln(&#92;det C) &#8211; &#92;frac{1}{2} &#92;Delta &#92;frac{&#92;partial}{&#92;partial &#92;lambda} C^{-1} &#92;Delta  &#92;nonumber &#92;&#92;<br />
&amp;=&amp; -&#92;frac{1}{2} &#92;mathrm{Tr} [C^{-1} C _ {,&#92;lambda}] + &#92;frac{1}{2}&#92;Delta C^{-1}C _ {,&#92;lambda}C^{-1} &#92;Delta<br />
&#92;end{eqnarray}</p>
<p>重复使用上述技巧，可以得出二阶导数<br />
&#92;[ (&#92;ln &#92;mathscr L) _ {,&#92;lambda&#92;lambda} = -&#92;Delta C^{-1}C _ {,&#92;lambda} C^{-1} C _ {,&#92;lambda} C^{-1}&#92;Delta + &#92;frac{1}{2} &#92;mathrm{Tr} [ C^{-1} C _ {,&#92;lambda} C^{-1} C _ {,&#92;lambda} ] +&#92;frac{1}{2} ( &#92;Delta C^{-1} C _ {,&#92;lambda&#92;lambda} C^{-1} &#92;Delta &#8211; &#92;mathrm {Tr} [ C^{-1} C _ {,&#92;lambda&#92;lambda} ] ) &#92;]</p>
<p>为了方便，定义一个 curvature，<br />
&#92;[ &#92;mathscr F = &#8211; &#92;frac{&#92;partial^2 &#92;ln &#92;mathscr L}{&#92;partial &#92;lambda^2} &#92;]</p>
<p>并且<br />
&#92;[ F _ {,&#92;lambda&#92;lambda} &#92;equiv &#92;langle &#92;mathscr F &#92;rangle = &#92;frac 1 2 &#92;mathrm{Tr} [ C _ {,&#92;lambda} C^{-1} C _ {,&#92;lambda} C^{-1} ] &#92;]</p>
<p>于是<br />
&#92;begin{equation}<br />
&#92;hat&#92;lambda = &#92;lambda^{(0)} + F^{-1} _ {&#92;lambda&#92;lambda} &#92;frac{&#92;Delta C^{-1}C _ {,&#92;lambda} C^{-1} &#92;Delta &#8211; &#92;mathrm {Tr} [ C^{-1} C _ {,&#92;lambda} ] }{ 2 }<br />
&#92;end{equation}</p>
<p>从这个 CMB 的例子可以更好的了解具体如何计算。按照我们一开始的想法，只要我们把按照这个过程多进行几次迭代就可以了。</p>
<p>但是上面所讲仅仅是一个参数的情况，那么对于多个参数的情况呢？</p>
<p>多参数的情况就变成了</p>
<p>&#92;begin{equation}<br />
&#92;hat &#92;lambda _ &#92;alpha^{(0)} + F^{-1} _ {&#92;alpha&#92;beta} &#92;frac{ &#92;Delta C^{-1} C _ {,&#92;beta} C^{-1} &#92;Delta &#8211; &#92;mathrm{Tr} [ C^{-1} C _ {,&#92;beta} ] }{ 2 }<br />
&#92;end{equation}</p>
<p>其中原来的 curvature 变成了 Fisher matrix<br />
&#92;[ F _ {&#92;alpha&#92;beta} &#92;equiv &#92;langle &#8211; &#92;frac{ &#92;partial^2 (&#92;ln &#92;mathscr L) }{ &#92;partial &#92;lambda _ {&#92;alpha} &#92;partial &#92;lambda _ {&#92;beta} } &#92;rangle = &#92;frac12&#92;mathrm{Tr}[ C _ {,&#92;alpha} C^{-1} C _ {,&#92;beta} C^{-1} ] &#92;]</p>
<p>到此为止，这种方法告诉我们其实我们不需要曲完整的求解整个参数空间中的 likelihood function，而只需要估计一个参数空间的点，然后通过迭代的方法就可以了。这样只需要求解一个局域的参数空间而已。</p>
<p>下一步就是要得到参数误差。其实我们已经假定了数据是 Gaussian 的，所以只需要按照 Gaussian 分布来给定误差就可以了。</p>
<p>因此 variance of estimator 就是<br />
&#92;[ &#92;langle (&#92;hat&#92;lambda _ &#92;alpha &#8211; &#92;bar &#92;lambda _ &#92;alpha)(&#92;hat &#92;lambda _ &#92;beta &#8211; &#92;bar &#92;lambda _ &#92;beta) &#92;rangle = (F^{-1}) _ {&#92;alpha&#92;beta} &#92;]</p>
<p style="background:#f0ffff;margin:5px 15px 5px 20px;border:1px solid lightgreen;border-left:8px solid lightgreen;border-right:8px solid lightgreen;padding:2px 5px 2px 5px;">
<em>Modern Cosmology</em> P 367 中有关于为什么我们这里求解的 \(\hat\lambda\) 的期望值正好等于真正的理论值 \(\bar \lambda\) 的证明。这个证明从一方面说明了我们按照 Gaussian 分布给出结果的误差是正确的。
</p>
<p>Fisher matrix 变得非常重要，因为 Fisher matrix 不仅仅要用来计算参数空间极值，还直接决定了我们的数据拟合结果的好坏。下一篇 post 我们就来看看 Fisher matrix 的计算方法。</p>
<hr />
<p style="background:#f0ffff;margin:5px 15px 5px 20px;border:1px solid lightblue;border-left:8px solid lightpink;padding:2px 5px 2px 5px;">
本文没有 flag。</p>
<div class='yarpp-related-rss'>
<hr /><p><big><strong><font color="#ff6600">长程相关文章:</font></strong></big></p><ol>
<li><a href="http://multiverse.lamost.org/blog/4364" rel="bookmark" title="宇宙学中的统计方法【丙】">宇宙学中的统计方法【丙】 </a><hr /></li>
<li><a href="http://multiverse.lamost.org/blog/2970" rel="bookmark" title="宇宙学中的统计方法【乙】">宇宙学中的统计方法【乙】 </a><hr /></li>
<li><a href="http://multiverse.lamost.org/blog/2918" rel="bookmark" title="宇宙学中的统计方法【甲】">宇宙学中的统计方法【甲】 </a><hr /></li>
</ol></p>
</div>
]]></content:encoded>
			<wfw:commentRss>http://multiverse.lamost.org/blog/4389/feed</wfw:commentRss>
		<slash:comments>0</slash:comments>
		</item>
		<item>
		<title>宇宙学中的统计方法【丙】</title>
		<link>http://multiverse.lamost.org/blog/4364</link>
		<comments>http://multiverse.lamost.org/blog/4364#comments</comments>
		<pubDate>Sat, 01 Dec 2012 12:45:45 +0000</pubDate>
		<dc:creator><![CDATA[时见疏星]]></dc:creator>
				<category><![CDATA[天尽头的纸条]]></category>
		<category><![CDATA[Statistics]]></category>
		<category><![CDATA[宇宙学]]></category>
		<category><![CDATA[物理]]></category>

		<guid isPermaLink="false">http://multiverse.lamost.org/blog/?p=4364</guid>
		<description><![CDATA[宇宙学中的统计方法笔记系列，第三篇：Galaxy Survey 中的统计方法。 系列文章目录： 宇宙学中的统计方法【甲】 宇宙学中的统计方法【乙】 宇宙学中的统计方法【丙】 宇宙学中的统计方法【丁】 【乙】中讲到的是 CMB 的统计。CMB 是一个二维面上的连续的温度场，而且是我们做了简单的假设说是 Gaussian 分布的。Galaxy Survey 跟 CMB 有很大的不同，它是三维空间中的分立的星系分布，而且这里 Non-Gaussian 很重要。 Galaxy Survey 的数据 Galaxy survey 是这样进行的：先把要进行巡天的天空分成足够小的区域，每个小区域有足够多的星系用来统计。然后都每个区域进行计数，分别除以每个小区域的体积就是星系的数密度，平均数密度就是总星系个数除以总体积。 数学上，Tegmark 提出了一个 galaxy survey 中的一个像素点上的数据的定义 &#92;begin{equation} &#92;Delta_i = &#92;int&#92;mathrm d^3x &#92;psi_i(&#92;vec x) &#92;left[ &#92;frac{n(&#92;vec...<div class='yarpp-related-rss'>
<hr />
<big><strong><font color="#ff6600">长程相关文章:</font></strong></big><ol>
<li><a href="http://multiverse.lamost.org/blog/4389" rel="bookmark" title="宇宙学中的统计方法【丁】">宇宙学中的统计方法【丁】 </a><hr /></li>
<li><a href="http://multiverse.lamost.org/blog/2970" rel="bookmark" title="宇宙学中的统计方法【乙】">宇宙学中的统计方法【乙】 </a><hr /></li>
<li><a href="http://multiverse.lamost.org/blog/2918" rel="bookmark" title="宇宙学中的统计方法【甲】">宇宙学中的统计方法【甲】 </a><hr /></li>
</ol>
</div>
]]></description>
				<content:encoded><![CDATA[<p>宇宙学中的统计方法笔记系列，第三篇：Galaxy Survey 中的统计方法。<span id="more-4364"></span></p>

<p>系列文章目录：</p>
<ul>
<li><a href="http://multiverse.lamost.org/blog/2918">宇宙学中的统计方法【甲】</a></li>
<li><a href="http://multiverse.lamost.org/blog/2970">宇宙学中的统计方法【乙】</a></li>
<li><a href="http://multiverse.lamost.org/blog/4364">宇宙学中的统计方法【丙】</a></li>
<li><a href="http://multiverse.lamost.org/blog/4389">宇宙学中的统计方法【丁】</a></li>
</ul>
<hr />
<p>【乙】中讲到的是 CMB 的统计。CMB 是一个<strong>二维</strong>面上的<strong>连续</strong>的温度场，而且是我们做了简单的假设说是 <strong>Gaussian</strong> 分布的。Galaxy Survey 跟 CMB 有很大的不同，它是<strong>三维</strong>空间中的<strong>分立</strong>的星系分布，而且这里 <strong>Non-Gaussian</strong> 很重要。</p>
<h2>Galaxy Survey 的数据</h2>
<p>Galaxy survey 是这样进行的：先把要进行巡天的天空分成足够小的区域，每个小区域有足够多的星系用来统计。然后都每个区域进行计数，分别除以每个小区域的体积就是星系的数密度，平均数密度就是总星系个数除以总体积。</p>
<p>数学上，Tegmark 提出了一个 galaxy survey 中的一个像素点上的数据的定义<br />
&#92;begin{equation}<br />
&#92;Delta_i = &#92;int&#92;mathrm d^3x &#92;psi_i(&#92;vec x) &#92;left[ &#92;frac{n(&#92;vec x) &#8211; &#92;bar n(&#92;vec x)}{&#92;bar n(&#92;vec x)} &#92;right] &#92;label{eqn-def-pixeldata}<br />
&#92;end{equation}<br />
其中 &#92;(n(&#92;vec x)&#92;) 是位置 &#92;(&#92;vec x&#92;) 处的星系数密度，&#92;(&#92;bar n(&#92;vec x)&#92;) 是平均数密度，&#92;(&#92;psi_i(&#92;vec x)&#92;) 是不同的区域的权重。<br />
对于 &#92;(&#92;psi_i(&#92;vec x)&#92;) 的选择根据情况而定，其中有两种选择，分别是实空间里的和 Fourier 空间里的，<br />
&#92;[<br />
&#92;psi_i^{&#92;text{CIC}}(&#92;vec x) = &#92;left&#92;{<br />
&#92;begin{array}{ll}<br />
&#92;bar n(&#92;vec x) &amp;&#92;mbox{if &#92;(&#92;vec x&#92;) is in the &#92;(i&#92;)th sub-volume}&#92;&#92;<br />
0      &amp;&#92;mbox{otherwise}<br />
&#92;end{array}<br />
&#92;right.<br />
&#92;]<br />
这个权重是说，在考虑某个点的数据的时候，仅仅考虑这个点上的星系分布，其他的点处的星系分布不会影响当前位置的星系数密度。<br />
而 Fourier 空间中的写法是<br />
&#92;[<br />
&#92;psi_i^{&#92;text{Fourier}}(&#92;vec x) = &#92;frac{e^{i&#92;vec k_i &#92;cdot &#92;vec x}}{V}&#92;left&#92;{<br />
&#92;begin{array}{ll}<br />
1 &amp;&#92;mbox{&#92;(&#92;vec x&#92;) inside the survey volume} &#92;&#92;<br />
0 &amp;&#92;mbox{&#92;(&#92;vec x&#92;) outside survey volume}<br />
&#92;end{array}<br />
&#92;right.<br />
&#92;]</p>
<p style="background:#f0ffff;margin:5px 15px 5px 20px;border:1px solid lightblue;border-left:8px solid lightblue;padding:2px 5px 2px 5px;">
扩充两种情况的物理。 flag 1
</p>
<h2>Galaxy Survey 的 likelihood</h2>
<p>因为结构形成的理论比较复杂，星系的分布也是一个高度非线性的体系。所以想要写出一个简单的 likelihood 的表达式是很难的。</p>
<p>定义 &#92;(&#92;Delta_i(&#92;vec x)&#92;) 为某个像素点的 fractional overdensity，这便是我们测量的量。物理上讲，我们可以知道 &#92;(&#92;Delta_i(x)&#92;) 的期望值应该是 0。我们可以定义出一个 covariance matrix<br />
&#92;[ &#92;langle&#92;Delta_i &#92;Delta_j^*&#92;rangle = (C_S)_{ij} + (C_N)_{ij} &#92;]</p>
<p>这很像是 CMB 数据分析的情况。</p>
<h2>Covariance Matrix</h2>
<p>Galaxy survey 与 CMB 不同的是，covariance matrix  更容易得到。</p>
<p style="background:#f0ffff;margin:5px 15px 5px 20px;border:1px solid lightblue;border-left:8px solid lightblue;padding:2px 5px 2px 5px;">
根据后面的章节补充 covariance matrix 的获得。补充无信号的时候 \(\langle n^2(\vec x) \rangle\) 与 \({\bar n}^2\) 并不相等。 flag 2
</p>
<h2>Window Function</h2>
<p>如果把方程 (&#92;ref{eqn-def-pixeldata}) 重新写成<br />
&#92;[ &#92;Delta_i = &#92;int&#92;mathrm d^3x &#92;psi_i(&#92;vec x) &#92;delta(&#92;vec x) &#92;]<br />
即重定义了中括号里面的部分。&#92;(&#92;delta(&#92;vec x)&#92;) 是 overdensity 。<br />
如此，covaricance matrix 变成了</p>
<p>&#92;begin{eqnarray}<br />
({&#92;bf C_S})_{ij} &amp;=&amp; &#92;langle &#92;Delta_i&#92;Delta_j &#92;rangle &#92;vert _{&#92;text{no noise}} &#92;nonumber&#92;&#92;<br />
&amp;=&amp; &#92;int &#92;mathrm d x^3&#92;mathrm dx&#8217;^3 &#92;psi_i(&#92;vec x) &#92;psi_j(&#92;vec x&#8217;) &#92;langle &#92;delta(&#92;vec x) &#92;delta(&#92;vec x&#8217;)&#92;rangle &#92;nonumber&#92;&#92;<br />
&amp;=&amp; &#92;int &#92;mathrm d x^3&#92;mathrm dx&#8217;^3 &#92;psi_i(&#92;vec x) &#92;psi_j(&#92;vec x&#8217;) &#92;xi(&#92;vec x &#8211; &#92;vec x&#8217;)&#92;nonumber<br />
&#92;end{eqnarray}</p>
<p>其中利用了</p>
<p>&#92;begin{equation}<br />
&#92;xi(&#92;vec x -&#92;vec x&#8217;) &#92;equiv &#92;langle &#92;delta(&#92;vec x)&#92;delta(&#92;vec x&#8217;) &#92;rangle  = &#92;int &#92;mathrm d^3 &#92;frac{P(k)e^{i&#92;vec k&#92;cdot (&#92;vec x &#8211; &#92;vec x&#8217;)}}{(2&#92;pi)^3} &#92;label{eqn-def-corr-power}<br />
&#92;end{equation}</p>
<p>而这里的 &#92;(x(&#92;vec x &#8211; &#92;vec x&#8217;)&#92;) 实际上是 correlation function。而 correlation function 正好用来定义 power spectrum，即方程 (&#92;ref{eqn-def-corr-power}) 第二个等号。</p>
<p>&#92;begin{eqnarray}<br />
({&#92;bf C_S})_{ij} &amp;=&amp; &#92;int &#92;mathrm d x^3&#92;mathrm dx&#8217;^3 &#92;int &#92;frac{&#92;mathrm d^3k}{2&#92;pi}&#92;frac{&#92;mathrm d^3k&#8217;}{2&#92;pi}&#92;frac{&#92;mathrm d^3k&#8221;}{2&#92;pi} &#92;tilde&#92;psi_i(&#92;vec k) &#92;tilde&#92;psi_j^*(&#92;vec k&#8217;) P(k&#8221;) e^{i[&#92;vec k+&#92;vec l&#8221;]&#92;cdot &#92;vec x &#8211; i[&#92;vec k&#8217; + &#92;vec k&#8221;]&#92;cdot &#92;vec x&#8217;} &#92;nonumber&#92;&#92;<br />
&amp;=&amp; &#92;int &#92;frac{&#92;mathrm d^3k}{(2&#92;pi)^3} P(k)&#92;tilde &#92;psi_i(&#92;vec k) &#92;tilde &#92;psi_j^*(&#92;vec k) &#92;label{eqn-covmat}<br />
&#92;end{eqnarray}</p>
<p>分解 (&#92;ref{eqn-covmat}) 式为径向积分和立体角积分</p>
<p>&#92;begin{eqnarray}<br />
({&#92;bf C_S})_{ij} &amp;=&amp; &#92;int &#92;frac{&#92;mathrm dk}{k} &#92;int &#92;frac{&#92;mathrm d&#92;Omega_k}{4&#92;pi} &#92;frac{k^3 P(k)}{2&#92;pi^2} &#92;tilde &#92;psi_i(&#92;vec k) &#92;tilde &#92;psi_j^*(&#92;vec k) &#92;nonumber<br />
&#92;end{eqnarray}</p>
<p>这样可以把立体角积分的部分就是 window function 了。</p>
<p>&#92;[ W_{ij}(k) = &#92;int &#92;frac{&#92;mathrm d&#92;Omega_k}{4&#92;pi} &#92;tilde &#92;psi_i(&#92;vec k) &#92;tilde &#92;psi_j(&#92;vec k) &#92;]</p>
<p>从这里可以看到 galaxy survey 和 CMB 的相似之处： Window function 上，都是 weighting function 的 Fourier 变换的立体角积分，也就是立体角上的平均值，而剩余的项都与方向无关。</p>
<h3>Volume-Limited Survey</h3>
<p>这个例子是我们的巡天是限制在半径为 &#92;(R&#92;) 的区域内，并且选用 Fourier pixel 形式的 pixelization，那么 weighting function 在巡天范围之内可以写成<br />
&#92;[&#92;psi_i(&#92;vec x) = &#92;frac{e^{i&#92;vec k_i &#92;cdot &#92;vec x}}{V} &#92;]</p>
<p>做 Fourier 变换，得到<br />
&#92;[&#92;tilde &#92;psi_i(&#92;vec x) = &#92;int_{&#92;vert x&#92;vert &lt;r } &#92;mathrm d^3x &#92;frac{e^{i&#92;vec k_i &#92;cdot &#92;vec x}}{V} e^{-i&#92;vec k &#92;cdot &#92;vec x} &#92;]</p>
<p>积分<br />
&#92;[ &#92;tilde &#92;psi_i(&#92;vec k) = &#92;int x^2 &#92;mathrm dx &#92;int &#92;mathrm d&#92;Omega &#92;frac{e^{i&#92;vec k_i &#92;cdot &#92;vec x-i&#92;vec k &#92;cdot &#92;vec x}}{V} = &#92;frac{4&#92;pi}{V&#92;vert &#92;vec k -&#92;vec k_i&#92;vert }  &#92;int _0^R &#92;mathrm dx x&#92;sin(&#92;vert &#92;vec k &#8211; &#92;vec k_i&#92;vert x) &#92;]</p>
<p>最后<br />
&#92;[ &#92;tilde &#92;psi_i(&#92;vec k) = &#92;frac{4&#92;pi}{V(&#92;vert &#92;vec k &#8211; &#92;vec k_i &#92;vert)^3} [ -&#92;vert &#92;vec k -&#92;vec k_i &#92;vert R &#92;cos(&#92;vert &#92;vec k -&#92;vec k_i &#92;vert R) +&#92;sin(&#92;vert &#92;vec k -&#92;vec k_i &#92;vert R) ] &#92;]</p>
<p>做代换，&#92;(y&#92;equiv &#92;vert &#92;vec k -&#92;vec k_i &#92;vert R &#92;) ，&#92;(&#92;mu = &#92;cos &#92;phi_{&#92;vec k,&#92;vec k_i}&#92;)。然后将上面的 Fourier 空间的 weighting function 模方然后取角平均，得到 window function<br />
&#92;[ W_{ii}(k) = &#92;frac{(4&#92;pi R^3)^2}{V^2} &#92;int_{-1}^1 &#92;frac{&#92;mathrm d&#92;mu}{2} &#92;int_{0}^{2&#92;pi} &#92;frac{&#92;mathrm d&#92;phi}{2&#92;pi} &#92;frac{ (&#92;sin y &#8211; y &#92;cos y)^2 }{ y^6 } &#92;&#92;<br />
=&#92;frac{8&#92;pi^2 R^6}{V^2} &#92;int_{-1}^{1} &#92;frac{&#92;mathrm d&#92;mu}{y^6}(&#92;sin y &#8211; y &#92;cos y)^2 &#92;]</p>
<p style="background:#f0ffff;margin:5px 15px 5px 20px;border:1px solid lightblue;border-left:8px solid lightblue;padding:2px 5px 2px 5px;">
下面这个结果我没算，直接从书上抄来的。 flag 3</p>
<p>最后利用 &#92;(y&#92;) 和 &#92;(&#92;mu&#92;) 的关系换积分元，利用 &#92;(V = 4&#92;pi R^3 /3&#92;)<br />
&#92;[ W_{ii} = &#92;frac{9}{2k k_i R^2} &#92;int_{&#92;vert k &#8211; k_i&#92;vert R}^{&#92;vert k + k_i&#92;vert R} &#92;frac{&#92;mathrm dy}{y} j_1^2(y) &#92;]</p>
<p>这里出现了 Bessel 函数。</p>
<p>这个结果告诉我们一个很自然的结论，因为 Bessel 函数的原因，window function 会在比较大的 &#92;(k_i R&#92;) 的情况下，变得很尖锐，也就是说，最后为 covariance matrix 做贡献的，只有 &#92;(k = k_i&#92;) 附近的那些模；相反，如果 &#92;(k_i R&#92;) 比较小，那么 window function 的展宽比较大，这样就是说，对于这样情况，covariance matrix 的贡献来自于大多数模。</p>
<p>下面是在这种巡天中，对其<strong>Covariance Matix 的几点讨论</strong></p>
<p>从 window function，我们可以得到 covariance matrix。</p>
<p style="background:#f0ffff;margin:5px 15px 5px 20px;border:1px solid lightblue;border-left:8px solid lightblue;padding:2px 5px 2px 5px;">
具体过程暂略。flag 4
</p>
<p>当 &#92;(k_i R &#92;gt 1&#92;) 时，信号 matrix 和 noise matrix 分别是</p>
<p>&#92;[(C_S)_{ii}&#92;sim &#92;frac{P(k_i)}{V}&#92;]</p>
<p>&#92;[ (C_N)_{ii}=&#92;frac{1}{&#92;bar n V} &#92;]</p>
<p>这样得到一个比较重要的比值</p>
<p>&#92;begin{equation}<br />
&#92;frac{ (C_S) } {(C_N) }&#92;vert _{ii} &#92;sim P(k_i) &#92;bar n<br />
&#92;end{equation}</p>
<p>这个结果是说，为了能够看清信号，功率谱越大越好，数密度平均值越大越好。实际上，在比较小的尺度上，这个信号噪声比已经很小了。</p>
<p>这种 window function 的几个例子可以看图：</p>
<p><img src="http://multiverse.lamost.org/blog/wp-content/uploads/2012/12/VolumeLimitedSurveyWindowFunction.jpg" alt="" title="Volume Limited Survey Window Function" width="550"/></p>
<p>对于大范围的 pixel，也就是小的 &#92;(k_i&#92;)，几乎所有的模都会对我们的 covariance matrix 有影响，而对于小范围的，也就是大的 &#92;(k_i&#92;)，只有接近 &#92;(k_i&#92;) 的才会对 covariance matrix 有影响。</p>
<h3>Pencil-Beam Survey</h3>
<p>Pencil-Beam Survey 就是无广度但是有深度的巡天，所探测的区域在 3D 上看来，像支铅笔，故名。</p>
<p>写成数学形式，需要用到 step function &#92;(&#92;Theta()&#92;)，通过 step function 方法可以构造出在一个在 &#92;(z&#92;) 在 &#92;([-L/2,L/2]&#92;) 内的圆柱体，具体形式是</p>
<p>&#92;[ &#92;psi_i(&#92;vec x) = &#92;frac{1}{&#92;pi R^2 L} &#92;Theta (z+L/2)&#92;Theta(L/2 -z)&#92;Theta(R^2 &#8211; x^2 -y^2) &#92;]</p>
<p>对于这种情况，我们同样可以写出 weighting function 的 Fourier 变换，记 &#92;(&#92;vec q  = &#92;vec k_i &#8211; &#92;vec k&#92;)。<br />
&#92;[ &#92;tilde&#92;psi_i(&#92;vec k) = &#92;int &#92;frac{&#92;mathrm d^3x}{&#92;pi R^2 L}e^{i(&#92;vec k_i &#8211; &#92;vec k)&#92;cdot &#92;vec x} &#92;Theta (z+L/2)&#92;Theta(L/2 -z)&#92;Theta(R^2 &#8211; x^2 -y^2) &#92;]</p>
<p>这时候用柱坐标（积分元 &#92;(r&#92;mathrm dr&#92;mathrm d&#92;theta&#92;mathrm dz&#92;)）比较方便，</p>
<p>&#92;[&#92;tilde &#92;psi_i(&#92;vec k) = &#92;frac{1}{&#92;pi R^2 L} &#92;int_{-L/2}^{L/2}&#92;mathrm d z e^{iq_z z} &#92;int_{0}^{R}&#92;mathrm dr r&#92;int_0^{2&#92;pi}&#92;mathrm d&#92;theta e^{iq_r r&#92;cos&#92;theta} &#92;label{eqn-} &#92;]</p>
<p>通过写出各个分量的积分上下限，去掉了 step function。</p>
<p>利用如下的积分技巧<br />
&#92;[ &#92;int_0^&#92;infty &#92;mathrm dx x^{n-2} j_l^2(x) = 2^{n-4} &#92;pi &#92;frac{&#92;Gamma(l+n/2 &#8211; 1/2)&#92;Gamma(3-n)}{&#92;Gamma(l+5/2-n/2)&#92;Gamma^2(2-n/2)} &#92;]</p>
<p>其中 &#92;(&#92;Gamma(z) = &#92;int_0^{&#92;infty} &#92;mathrm dt t^{z-1}e^{-t}&#92;)。这样就可以把 weighting function 写成 SphericalBesselJ 函数(&#92;(j_n(z) = &#92;sqrt{&#92;pi/2} /&#92;sqrt{z} J_{n+1/2}(z) &#92;))和 Bessel 函数(&#92;(J_{n+1/2}&#92;))的形式了。</p>
<p>&#92;[ &#92;tilde &#92;psi_i(&#92;vec k) = &#92;frac{2}{R^2} j_0(q_z L/2)&#92;int_0^R &#92;mathrm dr r J_0(q_r r) &#92;]</p>
<p>利用 &#92;[ &#92;frac{&#92;mathrm d}{&#92;mathrm dx}[xJ_1(x)] = x J_0(x) &#92;] 把积分写出来</p>
<p>&#92;[ &#92;tilde &#92;psi_i(&#92;vec k) = &#92;frac{2}{(q_r R)} j_0(q_zL/2) J_1(q_rR) &#92;]</p>
<p>有了 Weighting function，就可以模仿之前的方法计算 window function 了。Window function 的行为由 Bessel related functions 来决定的。下图是从 <em>Modern Cosmology</em> 里面截取出来的一张图。图中用是当 &#92;(q_r = 0&#92;) 的特殊情况。</p>
<p><img src="http://multiverse.lamost.org/blog/wp-content/uploads/2012/12/PencilBeamSurveyWindowFunction.jpg" alt="" title="Pencil-Beam Survey Window Function" width="550"/></p>
<p>跟之前的情况不同的是，现在对于大范围的 pixel （小&#92;(k_i R&#92;)）来说，几乎所有的模都对 covariance matix 起作用，这与上面的球形的 volume-limited survey 是一样的，但是对于小范围的 pixel （大&#92;(k_i R&#92;)）来说，&#92;(k&#92;lt k_i&#92;) 大的模都会 covariance matrix 起作用，而之前的 volume-limited survey 却是只有 &#92;(k&#92;approx k_i&#92;) 的模才会对 covariance matrix 有贡献，原因就在于 pencil-beam 是长条状的，而 window function 是要对所有三个方向的模分量来平均的。在图中所示的情况下（&#92;(q_r  = 0&#92;)），如果是要取 &#92;(q_r&#92;) 和 &#92;(q_z&#92;) 的平均然后限制其大小在 &#92;(q_{&#92;text{limit}}&#92;) 内，自然 &#92;(q_z&#92;) 会比 &#92;(q_{&#92;text{limit}}&#92;) 大多了。所以即使对于较大的 &#92;(k_i R&#92;) 会有一些比 &#92;(k &#92;lt k_i&#92;) 的模贡献进来。</p>
<hr />
<p style="background:#f0ffff;margin:5px 15px 5px 20px;border:1px solid lightblue;border-left:8px solid lightpink;padding:2px 5px 2px 5px;">
本文共有 4 个 flag。请仔细检阅并消除所有 flag。
</p>
<p></r></p>
<div class='yarpp-related-rss'>
<hr /><p><big><strong><font color="#ff6600">长程相关文章:</font></strong></big></p><ol>
<li><a href="http://multiverse.lamost.org/blog/4389" rel="bookmark" title="宇宙学中的统计方法【丁】">宇宙学中的统计方法【丁】 </a><hr /></li>
<li><a href="http://multiverse.lamost.org/blog/2970" rel="bookmark" title="宇宙学中的统计方法【乙】">宇宙学中的统计方法【乙】 </a><hr /></li>
<li><a href="http://multiverse.lamost.org/blog/2918" rel="bookmark" title="宇宙学中的统计方法【甲】">宇宙学中的统计方法【甲】 </a><hr /></li>
</ol></p>
</div>
]]></content:encoded>
			<wfw:commentRss>http://multiverse.lamost.org/blog/4364/feed</wfw:commentRss>
		<slash:comments>0</slash:comments>
		</item>
		<item>
		<title>宇宙学中的统计方法【乙】</title>
		<link>http://multiverse.lamost.org/blog/2970</link>
		<comments>http://multiverse.lamost.org/blog/2970#comments</comments>
		<pubDate>Sat, 01 Dec 2012 08:24:29 +0000</pubDate>
		<dc:creator><![CDATA[时见疏星]]></dc:creator>
				<category><![CDATA[天尽头的纸条]]></category>
		<category><![CDATA[Statistics]]></category>
		<category><![CDATA[宇宙学]]></category>
		<category><![CDATA[物理]]></category>

		<guid isPermaLink="false">http://multiverse.lamost.org/blog/?p=2970</guid>
		<description><![CDATA[宇宙学中的统计方法笔记系列，第二篇：CMB 中的统计方法。 系列文章目录： 宇宙学中的统计方法【甲】 宇宙学中的统计方法【乙】 宇宙学中的统计方法【丙】 宇宙学中的统计方法【丁】 继续前面的 likelihood 的讨论，不过现在要扩展到 CMB 中来。与前面的不同的地方是，之前的例子中，我们的测量是每次一个值的，但是在 CMB 的测量中，我们的数据是一个分布，而且之前的例子的每个数据点我们是有理论可以完全预测的，而在 CMB 中，我们的分布的一个特定的数据点，我们是没有理论来完整预测的，而是只有一个对所有点的统计的预测。 CMB 的数据记录和相关理论 CMB 测量方法和数据记录待补充。flag 1 CMB 的观测中，我们把天空分成很多像素点，针对每个像素点记录温度各项异性。下面的分析中我们使用的温度各项异性，是相对于平均温度的差异。 对于各项异性的理论预言，我们选择较为简单的 Gaussian 分布的情况，即每个像素点上的温度差异分布符合 Gaussian 分布。 单像素点的 likelihood 现在我们先建立数学描述。对于天空上的一个点，我们可以测量温度各项异性，其值为 &#92;(s&#92;)，而预测值（estimator）记做 &#92;(&#92;Delta&#92;)。跟前面的例子一样，我们同样会有一个代表预测结果可靠性的量（ Modern Cosmology 中把这个叫做 variance of the estimator）的量...<div class='yarpp-related-rss'>
<hr />
<big><strong><font color="#ff6600">长程相关文章:</font></strong></big><ol>
<li><a href="http://multiverse.lamost.org/blog/4389" rel="bookmark" title="宇宙学中的统计方法【丁】">宇宙学中的统计方法【丁】 </a><hr /></li>
<li><a href="http://multiverse.lamost.org/blog/4364" rel="bookmark" title="宇宙学中的统计方法【丙】">宇宙学中的统计方法【丙】 </a><hr /></li>
<li><a href="http://multiverse.lamost.org/blog/2918" rel="bookmark" title="宇宙学中的统计方法【甲】">宇宙学中的统计方法【甲】 </a><hr /></li>
</ol>
</div>
]]></description>
				<content:encoded><![CDATA[<p>宇宙学中的统计方法笔记系列，第二篇：CMB 中的统计方法。<span id="more-2970"></span></p>

<p>系列文章目录：</p>
<ul>
<li><a href="http://multiverse.lamost.org/blog/2918">宇宙学中的统计方法【甲】</a></li>
<li><a href="http://multiverse.lamost.org/blog/2970">宇宙学中的统计方法【乙】</a></li>
<li><a href="http://multiverse.lamost.org/blog/4364">宇宙学中的统计方法【丙】</a></li>
<li><a href="http://multiverse.lamost.org/blog/4389">宇宙学中的统计方法【丁】</a></li>
</ul>
<hr />
<p>继续前面的 likelihood 的讨论，不过现在要扩展到 CMB 中来。与前面的不同的地方是，之前的例子中，我们的测量是每次一个值的，但是在 CMB 的测量中，我们的数据是一个分布，而且之前的例子的每个数据点我们是有理论可以完全预测的，而在 CMB 中，我们的分布的一个特定的数据点，我们是没有理论来完整预测的，而是只有一个对所有点的统计的预测。</p>
<h2>CMB 的数据记录和相关理论</h2>
<p style="background:#f0ffff;margin:5px 15px 5px 20px;border:1px solid lightblue;border-left:8px solid lightblue;padding:2px 5px 2px 5px;">
CMB 测量方法和数据记录待补充。flag 1
</p>
<p>CMB 的观测中，我们把天空分成很多像素点，针对每个像素点记录温度各项异性。下面的分析中我们使用的温度各项异性，是相对于平均温度的差异。</p>
<p>对于各项异性的理论预言，我们选择较为简单的 Gaussian 分布的情况，即每个像素点上的温度差异分布符合 Gaussian 分布。</p>
<h2>单像素点的 likelihood</h2>
<p>现在我们先建立数学描述。对于天空上的一个点，我们可以测量温度各项异性，其值为 &#92;(s&#92;)，而预测值（estimator）记做 &#92;(&#92;Delta&#92;)。跟前面的例子一样，我们同样会有一个代表预测结果可靠性的量（ <em>Modern Cosmology</em> 中把这个叫做 variance of the estimator）的量 &#92;(C_N&#92;)，类似前面的例子，对于 &#92;(s&#92;) 和 &#92;(&#92;Delta&#92;) 同样有一个分布，<br />
&#92;[ P[s] = &#92;frac{1}{&#92;sqrt{ 2&#92;pi C_N }} &#92;exp&#92;left( -&#92;frac{(&#92;Delta &#8211; s)^2}{2C_N}&#92;right) &#92;]<br />
对于理论预测，如果我们取暴涨模型所给定的 Gaussian 分布，那么就有下面的这个关于 &#92;(S&#92;) 的分布，其中参量有 &#92;(s&#92;) 和 &#92;(C_S&#92;)<br />
&#92;[ P[&#92;theta(&#92;Delta,s)] = &#92;frac{1}{&#92;sqrt{2&#92;pi C_S}}&#92;exp&#92;left( -&#92;frac{s^2}{2C_S}&#92;right) &#92;]</p>
<p>现在，我们关心的两个量是 &#92;(&#92;Delta&#92;) 和 &#92;(C_S&#92;)，因为 &#92;(&#92;Delta&#92;) 是我们要的温度各项异性值，而 &#92;(C_S&#92;) 直接跟我们后面要了解的一个量 &#92;(C_l&#92;) 关联，&#92;(C_l&#92;) 是我们要的最终结果，而 &#92;(s&#92;) 这样的量我们并不关心。所以，现在这种情况下，我们需要求的 likelihood 其实是 &#92;(P[&#92;Delta|C_S]&#92;)，也就是给定一个带有参数 &#92;(C_l&#92;) 的理论，得到数据 &#92;(&#92;Delta&#92;) 的概率。<br />
那么根据概率论（之前的例子中有具体计算步骤）<br />
&#92;[ P[&#92;Delta|C_S] = &#92;sum_s P[&#92;Delta|s] &#92;times P[s|C_S] &#92;]</p>
<p style="background:#f0ffff;margin:5px 15px 5px 20px;border:1px solid lightblue;border-left:8px solid lightblue;padding:2px 5px 2px 5px;">
在 <em>Modern Cosmology</em> 中，Scott Dodelson 并没有对这里的 likelihood 进行很多解释。这里 flag 一下，提醒以后注意回来检查精简这段描述。flag 2
</p>
<p>于是 Likelihood function 是概率密度的积分<br />
&#92;[ {&#92;scr L} = &#92;int^&#92;infty_{-&#92;infty} &#92;mathrm ds &#92;frac{1}{&#92;sqrt{2&#92;pi C_S}}&#92;exp&#92;left( -&#92;frac{s^2}{2C_S}&#92;right) &#92;frac{1}{&#92;sqrt{ 2&#92;pi C_N }} &#92;exp&#92;left( -&#92;frac{(&#92;Delta &#8211; s)^2}{2C_N}&#92;right) &#92;]</p>
<p>定义 &#92;(C=C_S+C_N&#92;) 是 full covariance matrix，把  &#92;(s&#92;) 积分积掉，</p>
<p>&#92;begin{eqnarray}<br />
{&#92;scr L} &amp;=&amp; &#92;int &#92;mathrm ds &#92;frac{1}{2&#92;pi &#92;sqrt{C_S C_N}} &#92;exp&#92;left( -&#92;frac{s^2 C_N + (&#92;Delta &#8211; s)^2C_S}{2C_S C_N} &#92;right) &#92;&#92;<br />
&amp;=&amp; &#92;frac{1}{2&#92;pi&#92;sqrt{C_S C_N}} &#92;int &#92;mathrm ds &#92;exp&#92;left( -&#92;frac{ C(s- C_S &#92;Delta/C)^2 + &#92;Delta^2 (C_S C_N/C) }{2C_N C_S} &#92;right) &#92;&#92;<br />
&amp;=&amp; &#92;frac{1}{&#92;sqrt{2&#92;pi C_S}}&#92;exp&#92;left( &#8211; &#92;frac{&#92;Delta^2}{2C} &#92;right) &#92;int &#92;mathrm d(s &#8211; C_S&#92;Delta/C)&#92;exp&#92;left( &#8211; &#92;frac{C(s &#8211; C_S&#92;Delta/C)^2 }{2C_S C_N} &#92;right) &#92;&#92;<br />
&amp;=&amp; &#92;frac{1}{&#92;sqrt{2&#92;pi C}}&#92;exp&#92;left( -&#92;frac{&#92;Delta^2}{2C} &#92;right)<br />
&#92;end{eqnarray}</p>
<h2>多像素点情况</h2>
<p style="background:#f0ffff;margin:5px 15px 5px 20px;border:1px solid lightblue;border-left:8px solid lightblue;padding:2px 5px 2px 5px;">
待补充。详细说明为何可以使用矩阵形式。flag 3
</p>
<p>这样我们就得到了天空中一个像素点的情况，可以推广到 N 个像素点的情况，<br />
&#92;begin{equation}<br />
{&#92;scr L} = &#92;frac{1}{(2&#92;pi)^{N/2}(&#92;mathrm {det} &#92;bf C)^{1/2}} &#92;exp&#92;left( &#8211; &#92;frac{1}{2} &#92;bf &#92;Delta &#92;bf C^{-1} &#92;bf&#92;Delta &#92;right) &#92;label{eqn-multipixellikelihood}<br />
&#92;end{equation}</p>
<p>上式（方程(&#92;ref{eqn-multipixellikelihood})）中 &#92;(&#92;Delta&#92;) 是长度为 &#92;( N &#92;)测量数据矢量，而 &#92;(C&#92;) 是 &#92;(N&#92;times N&#92;) 的 full corariance matrix。</p>
<h2>Covariance Matrix</h2>
<p>上面出现的三个 covariance matrix 分别是 &#92;(C_S&#92;)，&#92;(C_N&#92;)，&#92;(C&#92;)。其中 &#92;(C_S&#92;) 是出现在 &#92;(s&#92;) 的分布中的，也就是说是理论上 &#92;(s&#92;) 的分布宽度，称之为 signal covariance matrix，与测量中的噪声无关。从 &#92;(C_S&#92;) 到 &#92;(C&#92;) 其实是个很复杂的过程，严格的说，&#92;(C&#92;) 中需要考虑到任意的两个 parameter 直接的关联。</p>
<p style="background:#f0ffff;margin:5px 15px 5px 20px;border:1px solid lightblue;border-left:8px solid lightblue;padding:2px 5px 2px 5px;">
详细说明如何关联。flag 4
</p>
<h3>Covariance Matrix 的求解</h3>
<p>如果我们之考虑 covariance matrix 的对角项，<br />
&#92;[ C_{S,ii} &#92;equiv &#92;langle s_i s_i &#92;rangle &#92;]<br />
其中元素<br />
&#92;[ s_i = &#92;int &#92;mathrm d  &#92;hat n&#92;Theta(&#92;hat n) B_i(&#92;hat n) &#92;]<br />
其中 &#92;(&#92;Theta(&#92;hat n)&#92;) 是温度背景，&#92;(B_i&#92;) 是 beam pattern，也就是代表信号的性质的量。对于每个像素点都要把所有的方向的光子都考虑进来。<br />
把 &#92;(s_i&#92;) 带入 &#92;(C_{S,ii}&#92;) 可以得到 covariance matrix</p>
<p>\[ \frac{C_{S,ii}}{T^2} = \int \mathrm d\hat n \int \mathrm d\hat n&#8217; B_i(\hat n)B_i(\hat n&#8217;) \sum_{lm} Y_{lm}(\hat n)\sum_{l&#8217;m&#8217;} Y_{l&#8217;m&#8217;}^*(\hat n&#8217;)\langle a_{lm}a_{l&#8217;m&#8217;}^* \rangle \]</p>
<p>其中用到了<br />
&#92;[ &#92;Theta(&#92;hat n) = &#92;sum_{i=1}^&#92;infty &#92;sum_{m=-l}^{l} a_{lm} T Y_{lm}(&#92;hat n) &#92;]</p>
<p style="background:#f0ffff;margin:5px 15px 5px 20px;border:1px solid lightblue;border-left:8px solid lightblue;padding:2px 5px 2px 5px;">
*Modern Cosmology* 中写 \(\Theta\) 时不含 \(T\)，但是书中 11.35 式却含有 \(T\)，所以我把 \(T\) 添加到了 \(\Theta\) 的分解中。 flag 5
</p>
<p>把下式带入 covariance matrix 的表达式<br />
&#92;[ &#92;langle a_{lm} &#92;rangle; &#92;langle a_{lm} a_{l&#8217;m&#8217;}^* &#92;rangle = &#92;delta_{ll&#8217;}&#92;delta_{mm&#8217;}C_l &#92;]<br />
把 &#92;(l&#8217;,m&#8217;&#92;) 的求和求出来<br />
&#92;[ &#92;frac{C_{S,ii}}{T^2} = &#92;int &#92;mathrm d&#92;hat n &#92;int &#92;mathrm d&#92;hat n&#8217; B_i(&#92;hat n) B_i(&#92;hat n&#8217;) &#92;sum_{l} C_l &#92;sum_m Y_{lm}(&#92;hat n) Y_{lm}^*(&#92;hat n&#8217;) &#92;]</p>
<p>我们知道球谐函数有如下性质<br />
&#92;[ &#92;sum_m Y_{lm}(&#92;hat n)Y_{lm}^*(&#92;hat n&#8217;) = (2l+1) P_l (&#92;hat n&#92;cdot  &#92;hat n&#8217;)/4&#92;pi &#92;]<br />
定义<br />
&#92;[ W_{l,ii} = &#92;int &#92;mathrm d&#92;hat n&#92;int &#92;mathrm d&#92;hat n&#8217; B_i(&#92;hat n)B_i(&#92;hat n&#8217;) P_l(&#92;hat n&#92;cdot &#92;hat n&#8217;) &#92;]<br />
其中的 &#92;(&#92;hat n &#92;cdot &#92;hat n&#8217;&#92;) 可以写成 &#92;(&#92;cos(x)&#92;)，其中 &#92;(x&#92;) 是 &#92;(&#92;hat n&#92;) 和 &#92;(&#92;hat n&#8217;&#92;) 之间所夹的弧长。这样我们可以在一个二维平面上定义两个矢量，&#92;(&#92;vec x&#92;) 和 &#92;(&#92;vec x&#8217;&#92;)，使得  &#92;( &#92;cos(x) = &#92;cos(|&#92;vec x &#8211; &#92;vec x&#8217;|) &#92;)，即 &#92;(&#92;hat n&#92;cdot &#92;hat n&#8217; = &#92;cos(&#92;vec x &#8211; &#92;vec x&#8217;)&#92;)<br />
于是<br />
&#92;[ W_{l,ii} = &#92;int &#92;mathrm d^2x&#92;int &#92;mathrm d^2 x&#8217; B_i(x) B_i(x&#8217;) P_l(&#92;cos(|&#92;vec x &#8211; &#92;vec x&#8217;|) ) &#92;]</p>
<p style="background:#f0ffff;margin:5px 15px 5px 20px;border:1px solid lightblue;border-left:8px solid lightblue;padding:2px 5px 2px 5px;">
为什么变成二次导数了？我求的是一次导数。回来看看。下面还是继续按照 *Modern Cosmology* 里面所讲的来写。 flag 6
</p>
<p>所以 covariance matrix 变成<br />
&#92;[ &#92;frac{C_{S,ii}}{T^2} = &#92;sum_l &#92;frac{2l+1}{4&#92;pi} C_l W_{l,ii} &#92;]</p>
<p>关于上面提到的 window function &#92;(W_{l,ii}&#92;)， 还可以继续化简。首先，我们把 Legendre polynomials 表达出来，不过这里要用一个近似，就是在 l 很大的时候， Legendre polynomials 近似变成 Bessel function.<br />
&#92;[ P_{l} (&#92;cos(|&#92;vec x &#8211; &#92;vec x&#8217;|)) &#92;rightarrow J_0 (l|&#92;vec x &#8211; &#92;vec x&#8217;|) = &#92;frac{1}{2&#92;pi} &#92;int_0^{2&#92;pi} &#92;mathrm d&#92;phi &#92;exp{-il |&#92;vec x &#8211; &#92;vec x&#8217;| &#92;cos&#92;phi} &#92;]<br />
其中 &#92;(&#92;phi&#92;) 的意思是 &#92;(l&#92;) 和 &#92;(&#92;vec x &#8211; &#92;vec x&#8217;&#92;) 之间的额夹角。&#92;(l&#92;) 的方向可以选做某条坐标轴的方向比较方便。<br />
这样我们就可以把 window function 简化成<br />
&#92;[ W_{l,ii} = &#92;frac{1}{2&#92;pi} &#92;int_0^{2&#92;pi}&#92;mathrm d&#92;phi |&#92;tilde B_i(&#92;vec l)|^2 &#92;]<br />
其中<br />
&#92;[ &#92;tilde B_i(&#92;vec l) &#92;equiv &#92;int &#92;mathrm d^2x B_i(&#92;vec x)e^{-i &#92;vec l &#92;vec x} &#92;]<br />
是 &#92;(B_i&#92;) 的 Fourier 变换。</p>
<p>这样我们就可以把 covariance matrix 的对角项表示出来了，选择特定的 window function，就可以求解。</p>
<p>但是这只是对角项，实际上非对角项也是存在的，严格的计算需要把非对角项也包括进来。</p>
<h3>Window Function 的例子</h3>
<h4>Gaussian Beam</h4>
<p>对于 Guassian beam 的情况，beam pattern 写作<br />
&#92;[ B_i(&#92;vec x) = &#92;frac{1}{2&#92;pi &#92;sigma} &#92;exp&#92;left( -&#92;frac{(&#92;vec x -&#92;vec x_i)^2}{2&#92;sigma^2} &#92;right) &#92;]<br />
先令 &#92;(&#92;vec x_i = 0&#92;)，方便 Fourier 变换。<br />
Fourier 变换得到<br />
&#92;[ &#92;tilde B_i(&#92;vec l) =&#92;frac{1}{2&#92;pi &#92;sigma^2} &#92;int &#92;mathrm d^2x e^{-i&#92;vec l &#92;cdot&#92;vec x} &#92;exp&#92;left( -&#92;frac{x^2}{2&#92;sigma^2} &#92;right) = e^{-l^2&#92;sigma^2/2} &#92;]<br />
因为 Fourier 变换之后并不涉及 &#92;(&#92;vec l&#92;) 方向，所以 window function 可以立刻得出来<br />
&#92;[ W_{l,ii} = e^{-l^2&#92;sigma^2} &#92;]</p>
<p>这个函数的行为我们都很熟悉，如下所示，</p>
<p><img src="http://multiverse.lamost.org/blog/wp-content/uploads/2012/12/expplot.jpg" width="500" /></p>
<p>也就是说对于很大的 &#92;(l&#92;)，window function 会消失。换句话说，因为很大 &#92;(l&#92;) 正好对应很小的角分辨率，所以就是说，对于那些角分辨率小于 beam 的宽度的时候，这部分对于 covariance matrix 的贡献就自动被 window function 过滤掉了。</p>
<p>下面是一个例子。左上图是实空间里面的 beam 的 pattern，右上图表示 beam 做 Fourier 展开后在 Fourier 空间中的 pattern，下部图表示 window function。</p>
<p><img src="http://multiverse.lamost.org/blog/wp-content/uploads/2012/12/GaussianBeam.png" alt="" title="GaussianBeam" width="550" /></p>
<h4>Differencing a Gaussian Beam</h4>
<p>Beam function 也可以选择如下形式<br />
&#92;[ B(x,y) = &#92;delta(y)[&#92;delta(x-x_0) &#8211; &#92;delta(x + x_0)] &#92;]<br />
这样的 beam function 意思是？</p>
<p>做 Fourier 变换，得到<br />
&#92;[ &#92;tilde B (&#92;vec l) = 2i&#92;sin(l_x x_0) &#92;]</p>
<p>带入 window function 得到<br />
&#92;begin{eqnarray}<br />
W_l &amp;=&amp; &#92;frac{1}{2&#92;pi} 4 &#92;int _0^{2&#92;pi} &#92;mathrm d&#92;phi &#92;sin^2(lx_0&#92;cos&#92;phi) &#92;&#92;<br />
&amp;=&amp; &#92;frac{1}{&#92;pi}&#92;int_0^{2&#92;pi} &#92;mathrm d&#92;phi (1-&#92;cos(2lx_0&#92;cos&#92;phi)) &#92;&#92;<br />
&amp;=&amp; 2(1-P_l[&#92;cos(2x_0)])<br />
&#92;end{eqnarray}<br />
这里又用了前面用过的 Bessel function 和 Legendre function 之间的近似。</p>
<p>那么如果 beam 的宽度不是无穷小，而是有限大的，那么前面的 &#92;(&#92;delta&#92;) 函数就变化成积分就好了，也就是说<br />
&#92;[ B(x,y) =  &#92;frac{ 2&#92;pi &#92;sigma^2 } &#92;int &#92;mathrm dx&#8217;&#92;mathrm dy&#8217;&#92;exp&#92;left( -&#92;frac{(x-x&#8217;)^2 + (y -y&#8217;)^2}{2&#92;sigma} &#92;right) &#92;times &#92;delta(y&#8217;) [&#92;delta(x&#8217; &#8211; x_0) &#8211; &#92;delta(x&#8217; + x_0)] &#92;]</p>
<p>那么相应的 window function 变换就是<br />
&#92;[ W_l = e^{-l^2&#92;sigma^2} (1 &#8211; P_l[&#92;cos(2x_0)]) &#92;]</p>
<p>下面是一个例子。左上图是实空间里面的 beam 的 pattern，右上图表示 beam 做 Fourier 展开后在 Fourier 空间中的 pattern，下部图表示 window function。</p>
<p><img src="http://multiverse.lamost.org/blog/wp-content/uploads/2012/12/DifferencingGaussianBeam.png" alt="" title="Differencing Gaussian Beam" width="550" /></p>
<p>下图是一个更加紧致的 beam 的情况。</p>
<p><img src="http://multiverse.lamost.org/blog/wp-content/uploads/2012/12/DifferencingGaussianBeam2.jpg" alt="" title="DifferencingGaussianBeam2" width="550" /></p>
<hr />
<p style="background:#f0ffff;margin:5px 15px 5px 20px;border:1px solid lightblue;border-left:8px solid lightpink;padding:2px 5px 2px 5px;">
本文共有 6 个 flag。请仔细检阅并消除所有 flag。</p>
<div class='yarpp-related-rss'>
<hr /><p><big><strong><font color="#ff6600">长程相关文章:</font></strong></big></p><ol>
<li><a href="http://multiverse.lamost.org/blog/4389" rel="bookmark" title="宇宙学中的统计方法【丁】">宇宙学中的统计方法【丁】 </a><hr /></li>
<li><a href="http://multiverse.lamost.org/blog/4364" rel="bookmark" title="宇宙学中的统计方法【丙】">宇宙学中的统计方法【丙】 </a><hr /></li>
<li><a href="http://multiverse.lamost.org/blog/2918" rel="bookmark" title="宇宙学中的统计方法【甲】">宇宙学中的统计方法【甲】 </a><hr /></li>
</ol></p>
</div>
]]></content:encoded>
			<wfw:commentRss>http://multiverse.lamost.org/blog/2970/feed</wfw:commentRss>
		<slash:comments>0</slash:comments>
		</item>
		<item>
		<title>宇宙学中的统计方法【甲】</title>
		<link>http://multiverse.lamost.org/blog/2918</link>
		<comments>http://multiverse.lamost.org/blog/2918#comments</comments>
		<pubDate>Mon, 25 Jun 2012 12:16:43 +0000</pubDate>
		<dc:creator><![CDATA[时见疏星]]></dc:creator>
				<category><![CDATA[天尽头的纸条]]></category>
		<category><![CDATA[Statistics]]></category>
		<category><![CDATA[宇宙学]]></category>
		<category><![CDATA[物理]]></category>

		<guid isPermaLink="false">http://multiverse.lamost.org/blog/?p=2918</guid>
		<description><![CDATA[本文是宇宙学统计中的非常非常小的一部分。是我刚刚读了一篇文章(arXiv:0911.3105)的一部分后所学到的。如有谬误，欢迎指出。2012-11-30补充了一个 Modern Cosmology 中的实例。此为系列文章第一篇：统计基础。 系列文章目录： 宇宙学中的统计方法【甲】 宇宙学中的统计方法【乙】 宇宙学中的统计方法【丙】 宇宙学中的统计方法【丁】 约定 假定我们的宇宙遵从特定的规律，可以设想这样的两种观测者。一种是自然之上的创世者们，比如叫他们宇宙定制公司，他们非常清楚宇宙所遵从的规律，而且也知道宇宙是在什么样的参数下运行；另一种是宇宙之内卑微的生存者，比如我们地球上这些渺小的人类，我们并不知道宇宙是精确的规律是什么，也不知道在某个规律下面宇宙的参数是如何设定的，我们只能实验和观测，更加难堪的是，在宇宙学中，我们基本上只能进行观测，想要尝试去改变一些宇宙的设定来得到某些结果，目前还只能出现在科幻小说之中。 那么对于宇宙定制公司的人们来说，他知道宇宙的精确的理论是 H ，（对于我们来说是个假设而已，因为从我们的角度来看就是个 Hypothesis，简称 H ），而我们生活的宇宙可以用一个模型 &#92;(&#92;theta(&#92;theta_1,&#92;theta_2,&#8230;)&#92;) 来描述，其中 &#92;(&#92;theta_i&#92;) 为模型参数，而且他们知道宇宙运行之后的数据 D，（比较幸运的是，对于很多数据 D，我们也是可以得到的，因为我们就限定 D 为我们可以得到的数据）。 基本概念 那么从宇宙定制公司的角度来看： 可以根据 H 来计算 &#92;(&#92;theta&#92;) 模型下的某个数据出现的理论概率，比如现在在一个范围 A 内，共有 M 颗1型超新星，和 N 颗2型超新星。他们可以计算在拿到了 m 颗1型超新星和...<div class='yarpp-related-rss'>
<hr />
<big><strong><font color="#ff6600">长程相关文章:</font></strong></big><ol>
<li><a href="http://multiverse.lamost.org/blog/4389" rel="bookmark" title="宇宙学中的统计方法【丁】">宇宙学中的统计方法【丁】 </a><hr /></li>
<li><a href="http://multiverse.lamost.org/blog/4364" rel="bookmark" title="宇宙学中的统计方法【丙】">宇宙学中的统计方法【丙】 </a><hr /></li>
<li><a href="http://multiverse.lamost.org/blog/2970" rel="bookmark" title="宇宙学中的统计方法【乙】">宇宙学中的统计方法【乙】 </a><hr /></li>
</ol>
</div>
]]></description>
				<content:encoded><![CDATA[<p>本文是宇宙学统计中的非常非常小的一部分。是我刚刚读了一篇文章(arXiv:0911.3105)的一部分后所学到的。如有谬误，欢迎指出。2012-11-30补充了一个 <em>Modern Cosmology</em>  中的实例。此为系列文章第一篇：统计基础。<span id="more-2918"></span></p>

<p>系列文章目录：</p>
<ul>
<li><a href="http://multiverse.lamost.org/blog/2918">宇宙学中的统计方法【甲】</a></li>
<li><a href="http://multiverse.lamost.org/blog/2970">宇宙学中的统计方法【乙】</a></li>
<li><a href="http://multiverse.lamost.org/blog/4364">宇宙学中的统计方法【丙】</a></li>
<li><a href="http://multiverse.lamost.org/blog/4389">宇宙学中的统计方法【丁】</a></li>
</ul>
<hr />
<h2>约定</h2>
<p>假定我们的宇宙遵从特定的规律，可以设想这样的两种观测者。一种是自然之上的创世者们，比如叫他们宇宙定制公司，他们非常清楚宇宙所遵从的规律，而且也知道宇宙是在什么样的参数下运行；另一种是宇宙之内卑微的生存者，比如我们地球上这些渺小的人类，我们并不知道宇宙是精确的规律是什么，也不知道在某个规律下面宇宙的参数是如何设定的，我们只能实验和观测，更加难堪的是，在宇宙学中，我们基本上只能进行观测，想要尝试去改变一些宇宙的设定来得到某些结果，目前还只能出现在科幻小说之中。</p>
<p>那么对于宇宙定制公司的人们来说，他知道宇宙的精确的理论是 H ，（对于我们来说是个假设而已，因为从我们的角度来看就是个 Hypothesis，简称 H ），而我们生活的宇宙可以用一个模型 &#92;(&#92;theta(&#92;theta_1,&#92;theta_2,&#8230;)&#92;) 来描述，其中 &#92;(&#92;theta_i&#92;) 为模型参数，而且他们知道宇宙运行之后的数据 D，（比较幸运的是，对于很多数据 D，我们也是可以得到的，因为我们就限定 D 为我们可以得到的数据）。</p>
<h2>基本概念</h2>
<p><strong>那么从宇宙定制公司的角度来看：</strong></p>
<p>可以根据 H 来计算 &#92;(&#92;theta&#92;) 模型下的某个数据出现的理论概率，比如现在在一个范围 A 内，共有 M 颗1型超新星，和 N 颗2型超新星。他们可以计算在拿到了 m 颗1型超新星和 n 颗2型超新星之后，随便抽取一颗是1型的概率，因为整个宇宙在任何时空点的配置他们都清楚的很。这种我们统统称之为计算 &#92;(P(D|&#92;theta(&#92;theta_1,&#92;theta_2,..))&#92;)，即 likelihood. 意思是说，我们现在知道一个模型&#92;(&#92;theta&#92;)和参数&#92;(&#92;theta_1,&#92;theta_2,&#8230;&#92;)，得到某个结果 D 的概率是多少。</p>
<p>这差不多是宇宙定制公司用的最多的计算了吧。</p>
<p>而<strong>对于我们来说</strong>，情况变得就复杂多了。我们只有观测数据，并不知道宇宙的理论 H 和具体的模型及参数 &#92;(&#92;theta(&#92;theta_1,&#92;theta_2,&#8230;)&#92;)。而我们希望通过这些观测了解到宇宙背后的理论和具体模型及参数。<br />
因此<strong>从我们的角度来看</strong>却只能计算 Posterior，记作 &#92;(P(&#92;theta|D)&#92;)，意思是说，我们有一堆观测数据 D ，那么一个特定的模型&#92;(&#92;theta&#92;)并且取某些特定的参数 &#92;(&#92;theta(&#92;theta_1,&#92;theta_2,&#8230;)&#92;)的概率是多少。</p>
<p>可以看到这样一种记法，| 是符合条件符合，可以直接读作&#8221;符合条件&#8221;，因为这个条件概率的条件放在后面。而 &#92;(P(x | y)&#92;) 的意思就是，给定 &#92;(y&#92;) 发生 &#92;(x&#92;) 的概率。</p>
<p>为了更明白，我重复 arXiv:0911.3105 中的一个例子。</p>
<blockquote><p>
  If you have an urn with N red balls and M blue balls and you draw one ball at the time then probability theory can tell you what are your chances of picking a red ball given that you have already drawn n red and m blue: P(D|H). However this is not what you want to do: you want to make a few drawn from the urn and use probability theory to tell you what is the red vs blue distribution inside the urn: P(H|D). In the Frequentist approach all you can compute is P(D|H).
</p></blockquote>
<p>这里 &#92;(P(D|H)&#92;) 是 likelihood， 而 &#92;(P(H|D)&#92;) 是 posterior. 可以明显的看到，likelihood 是指我们明了系统的详细配置的情况下计算某件事情发生的概率，这个很强大;而 posterior 是我们不知道系统的配置的情况下，可以根据很多的实验来计算出的一个概率。这个例子中提到，如果我们可以做无穷次实验，那么就可以计算 posterior，即使我们是生活在2012年的地球人。==~</p>
<h2>Likelihood 的例子</h2>
<p>从 <em>Modern Cosmology</em> 中（337页）取一个例子，稍加修改。算是一段插曲。</p>
<p>我们要测量自己的体重，作为科学工作者，大家肯定都知道要多次测量，去平均值，还要给出误差。那么平均值该如何求的呢？误差又该如何求的呢？</p>
<p>我们现在可以假定一个理论，说每次测量的体重有两部分组成，一个是体重的精确值 &#92;(theta_0&#92;)，另一个是噪音（noise）。如果我们假定测量是个 Gaussian distribution，<br />
&#92;[ P[D|&#92;theta(&#92;theta_0,&#92;sigma)] &#92;equiv &#92;scr L(D,&#92;theta(&#92;theta_0,&#92;sigma)) = &#92;frac {1}{ &#92;sqrt{2&#92;pi&#92;sigma^2}} exp&#92;left({-&#92;frac{(&#92;theta &#8211; &#92;theta_0)^2}{2&#92;sigma^2}}&#92;right) &#92;]<br />
那么精确值 &#92;(&#92;theta_0&#92;) 是分布的极值点，而每次测量的噪音的大小可以用分布中的 &#92;(&#92;sigma&#92;) 来表征。这样我们这个理论中有两个参数：&#92;(&#92;theta_0&#92;)， &#92;(&#92;sigma&#92;)。</p>
<p>上面的 &#92;(P[D|&#92;theta(&#92;theta_0,&#92;sigma)]&#92;) 是指的一次测量中，给定一个理论 &#92;(&#92;theta(&#92;theta_0,&#92;sigma)&#92;)，我们测得一个数据 &#92;(D&#92;) 的概率。但是实际上我们可能进行 N 次独立测量，这样的话，likelihood 应该是<br />
&#92;[ &#92;scr L(D,&#92;theta(&#92;theta_0,&#92;sigma)) = &#92;frac {1}{ (2&#92;pi&#92;sigma^2)^{N/2}} exp&#92;left({-&#92;frac{&#92;sum^{N}_{i=1}(&#92;theta_i &#8211; &#92;theta_0)^2}{2&#92;sigma^2}}&#92;right) &#92;]</p>
<p>但是，我们做实验的人并不想要上面所求的 &#92;( P[D|&#92;theta(&#92;theta_0,&#92;sigma)]&#92;)，相反，我们要的是 &#92;(P[&#92;theta(&#92;theta_0,&#92;sigma)|D]&#92;)。</p>
<p>概率论中，我们有<br />
&#92;[ P[A&#92;cap B] = P[A|B]P[B] = P[B|A]P[A] &#92;]<br />
这样我们就可以得到 likelihood 跟我们要求的量之间的关系。<br />
&#92;[ P[&#92;theta(&#92;theta_0,&#92;sigma)|D] = &#92;frac{ P[D|&#92;theta(&#92;theta_0,&#92;sigma)P[&#92;theta(&#92;theta_0,&#92;sigma)]] }{ P[D] } &#92;]</p>
<p>式中分母 &#92;(P[D]&#92;) 并不会影响我们的概率极值在 &#92;(&#92;theta_0 ~ &#92;sigma&#92;) 相空间的位置，所以我们暂时把这一项丢掉，剩下的分子上的 prior，即 &#92;(P[&#92;theta(&#92;theta_0,&#92;sigma)]&#92;) 项，我们可以假设是均匀分布的。这样我们就可以简化到下式，<br />
&#92;[ P[&#92;theta(&#92;theta_0,&#92;sigma)] &#92;sim &#92;scr L &#92;]</p>
<p>这样我们就把要求解的量 &#92;(P[&#92;theta(&#92;theta_0,&#92;sigma)]&#92;) 与 likelihood 联系起来了，而 likelihood 我们是可以写出表达式的。</p>
<p>那么下面我们就是要找到参数空间的最佳拟合点，也就是参数空间中概率最大的地方。分别对两个参数求导，&#92;(&#92;frac{&#92;partial &#92;scr L}{&#92;partial {&#92;theta_0}}&#92;)，&#92;(&#92;frac{&#92;partial &#92;scr L}{&#92;partial &#92;sigma}&#92;)。</p>
<p>高斯分布的情况下，情况就简单了。<br />
&#92;[ &#92;frac{&#92;partial &#92;scr L}{&#92;partial {&#92;theta_0}} = &#92;frac{&#92;sum^N_{i=1} (&#92;theta_i &#8211; &#92;theta_0) }{ &#92;sigma^2 (2&#92;pi&#92;sigma^2)^{N/2} }  &#92;exp &#92;left( -&#92;frac{&#92;sum^N_{i=1} (&#92;theta_i &#8211; &#92;theta_0)}{2&#92;sigma^2} &#92;right)&#92;]<br />
令上式为零，得到<br />
&#92;[ &#92;sum^N_{i=1}(&#92;theta_i &#8211; &#92;theta_0) = 0 &#92;]<br />
也就是说，&#92;(&#92;theta_0&#92;) 是 &#92;(&#92;theta_i&#92;) 的平均值，记做 &#92;(&#92;bar&#92;theta&#92;)。</p>
<p>这段的意思是说，如果我们做了一堆实验，那么实验的理论值（按照我们一开始提出的理论）应该是所有值的代数平均 &#92;(&#92;bar&#92;theta&#92;)。</p>
<p>对于另外一个参数 &#92;(&#92;sigma&#92;)，</p>
<p>&#92;[ &#92;frac{&#92;partial &#92;scr L}{&#92;partial &#92;sigma} = &#92;scr L &#92;left( -&#92;frac{N}{2&#92;sigma^2} + &#92;frac{&#92;sum^N_{i=1} (&#92;theta_i &#8211; &#92;theta_0)^2 }{2&#92;sigma^4} &#92;right) &#92;]</p>
<p>上式为零，得到<br />
&#92;[ &#92;sigma^2 = &#92;frac{&#92;sum^N_{i=1} (&#92;theta_i &#8211; &#92;theta_0) }{ N } &#92;]<br />
也就是说， &#92;(&#92;sigma^2&#92;) 是测量数据统计的方差。</p>
<p>这只是找到了参数空间的最佳拟合，这样的两个数据有时候并不够用，我们需要进一步写出更加方便的表达测量误差的方法，一个比较好的方法是看分布的半高宽，但是我们的表达式里面半高宽并不容易看出来，于是我们可以把e指数里面的求和式写开来，<br />
&#92;[ &#92;exp&#92;left( &#8211; &#92;frac{(&#92;theta_N &#8211; &#92;frac 1 2 &#92;theta_0)}{&#92;sigma^{2/N}} &#8211; &#92;cdots &#92;right) = &#92;exp&#92;left( &#8211; &#92;frac{(&#92;theta_N &#8211; &#92;theta_0)}{(2&#92;sigma)^{2/N}}&#92;right) &#92;cdots &#92;exp&#92;left( &#8211; &#92;frac{(&#92;theta_1 &#8211; &#92;theta_0)}{(2&#92;sigma)^{2/N}}&#92;right) &#92;]</p>
<p>这样我们可以把每个因子的e指数里面的二次项系数合起来，&#92;(N/&#92;sigma^2&#92;)，可以认为整个e指数的宽度是 &#92;( &#92;frac{&#92;sigma}{N^{1/2}} &#92;)。当然这只是一个大致的说法，详细的定义可以看概率论的书（？）或者看 <em>Modern Cosmology</em> P339。<br />
这个结果很合理，分布的越散，测量的可信度就越小，测量次数越多，测量的可信度就越大。</p>
<p>到此我们把理论值和误差都表达出来了，也就是说，我们的整个 likehood 的可以由两个两个参数，分别是 estimator &#92;(&#92;bar&#92;theta&#92;) 和 variance of estimator &#92;(&#92;frac{&#92;sigma}{N^{1/2}}&#92;)，来确定。那么，现在我们就可以放弃之前带有复杂求和式的表达形式，而重新定为一个更加简单的形式：<br />
&#92;[ &#92;scr L = &#92;frac{1}{&#92;sqrt {2&#92;pi C_N}} &#92;exp&#92;left( -&#92;frac{(&#92;theta &#8211; &#92;bar&#92;theta)}{2C_N} &#92;right) &#92;]<br />
其中用到 &#92;(&#92;sigma^2 = &#92;frac{&#92;sum^N_{i=1} (&#92;theta_i &#8211; &#92;bar&#92;theta)}{N}&#92;)。而 &#92;(C_N = &#92;frac{&#92;sigma^2}{N}&#92;)。</p>
<h2>&#92;(&#92;chi^2&#92;) fit / Chisquare fit</h2>
<p>现在宇宙学积累了很多的数据，而且现在的很多数据也都是很精确的。同时我们有很多的理论模型，各式各样的，很科幻的都有。那么我们如何把数据和理论结合起来呢？这就需要用到拟合，fit.</p>
<p>一个常用的技巧是 least square 拟合。这里我们用到的是 chisquare 拟合。</p>
<p>列出我们现在所拥有的:</p>
<ul>
<li>观测数据。这里我们使用1a超新星的例子。我们有这样一堆数据：超新星名字，超新星红移 &#92;(zo<br />
&#92;)，超新星亮度/distance modulus &#92;(do&#92;)，超新星的distance modulus error &#92;(e&#92;).</p>
</li>
<li>
<p>理论模型。这里使用最简单的 LCDM 作为例子。理论上可以计算红移对应的距离 &#92;(dt(z,H0,&#92;Omega m0,&#92;Omega d0,&#92;Omega k0) = c&#92;cdot (1+z)&#92;int &#92;frac{1}{H0&#92;sqrt{&#92;Omega m0 (1+zz)^3 + &#92;Omega d0 + &#92;Omega k0(1+zz)^2}}&#92;mathrm d zz&#92;)<br />
实际上 &#92;(dt&#92;) 并没有那么多独立参量。比如我们可以这样建立各个参量之间的关系：<br />
&#92;begin{eqnarray}<br />
&#92;Omega m0 + &#92;Omega d0 +&#92;Omega k0 &amp;=&amp; 1 &#92;&#92;<br />
&#92;end{eqnarray}<br />
如果是一个平坦的宇宙，那么我们还可以把 &#92;(&#92;Omega k0&#92;) 设成 0 . 为了适应不同的情况，我们就抽象的写成 &#92;(dt(z,x1,x2,&#8230;)&#92;). &#92;(z&#92;)是变量。</p>
</li>
</ul>
<p>那么我们可以定义这样一个量</p>
<p>&#92;begin{equation}<br />
&#92;chi^2(x1,x2) = &#92;sum_{l} &#92;frac{(do[i] &#8211; dt(z[i],x1,x2,&#8230;))^2}{&#92;sigma_i^2}<br />
&#92;end{equation}</p>
<p>其中 &#92;(&#92;sigma_i&#92;) 是第 i 个数据点的测量误差。</p>
<p>一旦这样定义，我们可以看到，如果我们的理论和数据完全符合，那么 &#92;(&#92;chi^2(x1,x2,&#8230;)=0&#92;). 但是，如果这样，很有可能发生了不正常的事情，实际观测和实验不太可能做到这样。但是很明显，如果 &#92;(&#92;chi^2&#92;) 太小，那么也不太正常，因为这很可能意味着对观测值的误差估计太大了等等。</p>
<p>那么多大的时候才比较好呢？如果观测有 n 个数据点，模型有 m 个参数，定义一个量 N = m &#8211; n. 当 &#92;(&#92;chi^2/N &#92;sim 1&#92;) 时，是比较正常的，因为这正好意味着数据点的 error bar 差不多都与理论曲线相交。</p>
<p>这样我们可以去遍历所有的数据点或者 steep 方法或者 MCMC 方法得到 &#92;(&#92;chi^2&#92;) 的最小值 &#92;(&#92;chi^2_{min}&#92;)，此时对于的参数为 &#92;(x1_m,x2_m,&#8230;&#92;). 这组参数就是我们这个模型在这组数据点下面的 best fit.</p>
<p>然后我们可以去绘制置信度的 contour . 即绘制在 &#92;(&#92;chi^2_{min}&#92;)，周围差别 &#92;(&#92;Delta&#92;chi^2&#92;) 的地方的曲线。对于不同的 N 值的 best fit 和不同的置信度，有不同的 &#92;(&#92;Delta&#92;chi^2&#92;) 值。</p>
<p>这些详细的技巧比如 covariance matrix 等等会在后续的 post 中出现。现在不再赘述。</p>
<hr />
<p><strong>我有一个<a href="http://cosmologytaskforce.github.com/CoChiSquare/">关于 Chisquare fit 的 git 项目</a>。这个所用到的理论基本上是中学生就可以理解的。<del>但是到2012年6月25日为止我依然感觉结果有些问题，虽然方法是正确的。</del><del></del></strong></p>
<hr />
<p>另外，如果你喜欢在豆瓣九点等这种地方读这篇文章，可以安装 math anywhere 插件，这样公式就可以显示了：<br />
https://chrome.google.com/webstore/detail/gebhifiddmaaeecbaiemfpejghjdjmhc</p>
<div class='yarpp-related-rss'>
<hr /><p><big><strong><font color="#ff6600">长程相关文章:</font></strong></big></p><ol>
<li><a href="http://multiverse.lamost.org/blog/4389" rel="bookmark" title="宇宙学中的统计方法【丁】">宇宙学中的统计方法【丁】 </a><hr /></li>
<li><a href="http://multiverse.lamost.org/blog/4364" rel="bookmark" title="宇宙学中的统计方法【丙】">宇宙学中的统计方法【丙】 </a><hr /></li>
<li><a href="http://multiverse.lamost.org/blog/2970" rel="bookmark" title="宇宙学中的统计方法【乙】">宇宙学中的统计方法【乙】 </a><hr /></li>
</ol></p>
</div>
]]></content:encoded>
			<wfw:commentRss>http://multiverse.lamost.org/blog/2918/feed</wfw:commentRss>
		<slash:comments>2</slash:comments>
		</item>
	</channel>
</rss>
